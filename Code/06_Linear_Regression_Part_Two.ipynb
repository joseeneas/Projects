{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROFESSIONAL CERTIFICATE IN DATA SCIENCE AND ANALYTICS\n",
    "# Linear Regression: Part Two\n",
    "\n",
    "This code snippet imports several essential Python libraries and modules commonly used for data analysis, statistical modeling, machine learning, and visualization. Additionally, it configures NumPy to suppress specific runtime warnings. Here's a breakdown of the imports and their purposes:\n",
    "\n",
    "### Library Imports:\n",
    "\n",
    "1. **`numpy` (`import numpy as np`)**:\n",
    "   - NumPy is a fundamental library for numerical computing in Python. It provides support for multi-dimensional arrays and a wide range of mathematical operations. The alias `np` is a standard convention for referencing NumPy functions. In this context, NumPy is likely used for handling numerical data, performing matrix operations, and implementing mathematical computations.\n",
    "\n",
    "2. **`pandas` (`import pandas as pd`)**:\n",
    "   - Pandas is a library designed for data manipulation and analysis. It introduces data structures like `DataFrame` and `Series`, which make it easy to handle structured data. The alias `pd` is a standard convention for referencing Pandas functions. It is commonly used for organizing, cleaning, and preprocessing datasets.\n",
    "\n",
    "3. **`matplotlib.pyplot` (`from matplotlib import pyplot as plt`)**:\n",
    "   - Matplotlib is a popular library for creating visualizations. The `pyplot` module provides a MATLAB-like interface for generating plots. The alias `plt` is a standard convention for referencing `pyplot`. It is typically used to create scatter plots, line graphs, histograms, and other visualizations.\n",
    "\n",
    "4. **`statsmodels.formula.api` (`import statsmodels.formula.api as smf`)**:\n",
    "   - Statsmodels is a library for statistical modeling and hypothesis testing. The `formula.api` module provides a high-level interface for specifying models using formulas (e.g., `y ~ x1 + x2`). It is particularly useful for performing linear regression and obtaining detailed model summaries, including coefficients, p-values, and RÂ² values.\n",
    "\n",
    "5. **`sklearn.linear_model.LinearRegression`**:\n",
    "   - This module from Scikit-learn provides tools for building linear regression models. The `LinearRegression` class implements Ordinary Least Squares (OLS) regression, allowing you to fit models, make predictions, and access model parameters like coefficients and intercepts.\n",
    "\n",
    "6. **`sklearn.feature_selection.RFE`**:\n",
    "   - Recursive Feature Elimination (RFE) is a feature selection technique provided by Scikit-learn. It iteratively removes the least important features based on a model's performance, helping to identify the most relevant predictors for a given task.\n",
    "\n",
    "7. **`sklearn.preprocessing.StandardScaler`**:\n",
    "   - The `StandardScaler` class is used to standardize features by removing the mean and scaling to unit variance. This preprocessing step is essential for many machine learning algorithms that are sensitive to the scale of input features.\n",
    "\n",
    "8. **`sklearn.decomposition.PCA`**:\n",
    "   - Principal Component Analysis (PCA) is a dimensionality reduction technique provided by Scikit-learn. It transforms the data into a lower-dimensional space while retaining as much variance as possible, which is useful for reducing complexity and improving computational efficiency.\n",
    "\n",
    "### NumPy Error Handling:\n",
    "\n",
    "- **`np.seterr(divide='ignore', invalid='ignore')`**:\n",
    "  - Configures NumPy to suppress warnings related to division by zero and invalid operations (e.g., `NaN` results). This is useful when working with datasets that may contain edge cases or missing values.\n",
    "\n",
    "- **`np.seterr(over='ignore', invalid='ignore')`**:\n",
    "  - Suppresses warnings related to overflow errors and invalid operations. This ensures that runtime warnings do not interrupt the execution of the code, especially when performing large-scale numerical computations.\n",
    "\n",
    "### Purpose:\n",
    "This setup prepares the environment for performing data analysis, statistical modeling, and machine learning tasks. The imported libraries provide tools for handling data, building models, selecting features, scaling inputs, and visualizing results. The NumPy error handling ensures that the code runs smoothly even when encountering numerical edge cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy                                   as np      # type: ignore\n",
    "import pandas                                  as pd      # type: ignore\n",
    "from   matplotlib                import pyplot as plt     # type: ignore\n",
    "import statsmodels.formula.api                 as smf     # type: ignore\n",
    "from   sklearn.linear_model      import LinearRegression  # type: ignore\n",
    "from   sklearn.feature_selection import RFE               # type: ignore\n",
    "from   sklearn.preprocessing     import StandardScaler    # type: ignore\n",
    "from   sklearn.decomposition     import PCA               # type: ignore\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore',over='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "This code snippet reads a CSV file named `mtcars.csv` located in the `data` directory and loads its contents into a Pandas DataFrame named `cars`. The `pd.read_csv` function is a versatile method provided by the Pandas library for reading comma-separated values (CSV) files and converting them into a structured DataFrame format.\n",
    "\n",
    "### Step-by-Step Explanation:\n",
    "\n",
    "1. **Reading the CSV File**:\n",
    "   - `pd.read_csv('data/mtcars.csv')`:\n",
    "     - The `read_csv` function takes the file path `'data/mtcars.csv'` as an argument and reads the contents of the file.\n",
    "     - By default, it assumes the file is in CSV format, with the first row containing column headers and subsequent rows containing data.\n",
    "     - The function automatically parses the data into rows and columns, creating a tabular structure.\n",
    "\n",
    "2. **Storing the Data**:\n",
    "   - The resulting DataFrame is assigned to the variable `cars`. A DataFrame is a two-dimensional, labeled data structure in Pandas, similar to a table in a relational database or a spreadsheet.\n",
    "\n",
    "3. **Displaying the Data**:\n",
    "   - The `cars` variable is referenced at the end of the code snippet. In a Jupyter Notebook or similar interactive environment, this will display the contents of the DataFrame. The output will show the column names and the first few rows of data, allowing you to inspect the structure and contents of the dataset.\n",
    "\n",
    "### Purpose:\n",
    "This code is typically used as the first step in a data analysis workflow. By loading the `mtcars.csv` file into a DataFrame, the data becomes accessible for further processing, such as cleaning, visualization, or statistical modeling. The `mtcars` dataset is a well-known dataset in the R programming community, often used for demonstrating regression analysis and other statistical techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mpg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cyl",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "disp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "drat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "wt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "qsec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "vs",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "am",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gear",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "carb",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "6a6fb1aa-d084-4328-8cbb-1998364acc2a",
       "rows": [
        [
         "0",
         "Mazda RX4",
         "21.0",
         "6",
         "160.0",
         "110",
         "3.9",
         "2.62",
         "16.46",
         "0",
         "1",
         "4",
         "4"
        ],
        [
         "1",
         "Mazda RX4 Wag",
         "21.0",
         "6",
         "160.0",
         "110",
         "3.9",
         "2.875",
         "17.02",
         "0",
         "1",
         "4",
         "4"
        ],
        [
         "2",
         "Datsun 710",
         "22.8",
         "4",
         "108.0",
         "93",
         "3.85",
         "2.32",
         "18.61",
         "1",
         "1",
         "4",
         "1"
        ],
        [
         "3",
         "Hornet 4 Drive",
         "21.4",
         "6",
         "258.0",
         "110",
         "3.08",
         "3.215",
         "19.44",
         "1",
         "0",
         "3",
         "1"
        ],
        [
         "4",
         "Hornet Sportabout",
         "18.7",
         "8",
         "360.0",
         "175",
         "3.15",
         "3.44",
         "17.02",
         "0",
         "0",
         "3",
         "2"
        ],
        [
         "5",
         "Valiant",
         "18.1",
         "6",
         "225.0",
         "105",
         "2.76",
         "3.46",
         "20.22",
         "1",
         "0",
         "3",
         "1"
        ],
        [
         "6",
         "Duster 360",
         "14.3",
         "8",
         "360.0",
         "245",
         "3.21",
         "3.57",
         "15.84",
         "0",
         "0",
         "3",
         "4"
        ],
        [
         "7",
         "Merc 240D",
         "24.4",
         "4",
         "146.7",
         "62",
         "3.69",
         "3.19",
         "20.0",
         "1",
         "0",
         "4",
         "2"
        ],
        [
         "8",
         "Merc 230",
         "22.8",
         "4",
         "140.8",
         "95",
         "3.92",
         "3.15",
         "22.9",
         "1",
         "0",
         "4",
         "2"
        ],
        [
         "9",
         "Merc 280",
         "19.2",
         "6",
         "167.6",
         "123",
         "3.92",
         "3.44",
         "18.3",
         "1",
         "0",
         "4",
         "4"
        ],
        [
         "10",
         "Merc 280C",
         "17.8",
         "6",
         "167.6",
         "123",
         "3.92",
         "3.44",
         "18.9",
         "1",
         "0",
         "4",
         "4"
        ],
        [
         "11",
         "Merc 450SE",
         "16.4",
         "8",
         "275.8",
         "180",
         "3.07",
         "4.07",
         "17.4",
         "0",
         "0",
         "3",
         "3"
        ],
        [
         "12",
         "Merc 450SL",
         "17.3",
         "8",
         "275.8",
         "180",
         "3.07",
         "3.73",
         "17.6",
         "0",
         "0",
         "3",
         "3"
        ],
        [
         "13",
         "Merc 450SLC",
         "15.2",
         "8",
         "275.8",
         "180",
         "3.07",
         "3.78",
         "18.0",
         "0",
         "0",
         "3",
         "3"
        ],
        [
         "14",
         "Cadillac Fleetwood",
         "10.4",
         "8",
         "472.0",
         "205",
         "2.93",
         "5.25",
         "17.98",
         "0",
         "0",
         "3",
         "4"
        ],
        [
         "15",
         "Lincoln Continental",
         "10.4",
         "8",
         "460.0",
         "215",
         "3.0",
         "5.424",
         "17.82",
         "0",
         "0",
         "3",
         "4"
        ],
        [
         "16",
         "Chrysler Imperial",
         "14.7",
         "8",
         "440.0",
         "230",
         "3.23",
         "5.345",
         "17.42",
         "0",
         "0",
         "3",
         "4"
        ],
        [
         "17",
         "Fiat 128",
         "32.4",
         "4",
         "78.7",
         "66",
         "4.08",
         "2.2",
         "19.47",
         "1",
         "1",
         "4",
         "1"
        ],
        [
         "18",
         "Honda Civic",
         "30.4",
         "4",
         "75.7",
         "52",
         "4.93",
         "1.615",
         "18.52",
         "1",
         "1",
         "4",
         "2"
        ],
        [
         "19",
         "Toyota Corolla",
         "33.9",
         "4",
         "71.1",
         "65",
         "4.22",
         "1.835",
         "19.9",
         "1",
         "1",
         "4",
         "1"
        ],
        [
         "20",
         "Toyota Corona",
         "21.5",
         "4",
         "120.1",
         "97",
         "3.7",
         "2.465",
         "20.01",
         "1",
         "0",
         "3",
         "1"
        ],
        [
         "21",
         "Dodge Challenger",
         "15.5",
         "8",
         "318.0",
         "150",
         "2.76",
         "3.52",
         "16.87",
         "0",
         "0",
         "3",
         "2"
        ],
        [
         "22",
         "AMC Javelin",
         "15.2",
         "8",
         "304.0",
         "150",
         "3.15",
         "3.435",
         "17.3",
         "0",
         "0",
         "3",
         "2"
        ],
        [
         "23",
         "Camaro Z28",
         "13.3",
         "8",
         "350.0",
         "245",
         "3.73",
         "3.84",
         "15.41",
         "0",
         "0",
         "3",
         "4"
        ],
        [
         "24",
         "Pontiac Firebird",
         "19.2",
         "8",
         "400.0",
         "175",
         "3.08",
         "3.845",
         "17.05",
         "0",
         "0",
         "3",
         "2"
        ],
        [
         "25",
         "Fiat X1-9",
         "27.3",
         "4",
         "79.0",
         "66",
         "4.08",
         "1.935",
         "18.9",
         "1",
         "1",
         "4",
         "1"
        ],
        [
         "26",
         "Porsche 914-2",
         "26.0",
         "4",
         "120.3",
         "91",
         "4.43",
         "2.14",
         "16.7",
         "0",
         "1",
         "5",
         "2"
        ],
        [
         "27",
         "Lotus Europa",
         "30.4",
         "4",
         "95.1",
         "113",
         "3.77",
         "1.513",
         "16.9",
         "1",
         "1",
         "5",
         "2"
        ],
        [
         "28",
         "Ford Pantera L",
         "15.8",
         "8",
         "351.0",
         "264",
         "4.22",
         "3.17",
         "14.5",
         "0",
         "1",
         "5",
         "4"
        ],
        [
         "29",
         "Ferrari Dino",
         "19.7",
         "6",
         "145.0",
         "175",
         "3.62",
         "2.77",
         "15.5",
         "0",
         "1",
         "5",
         "6"
        ],
        [
         "30",
         "Maserati Bora",
         "15.0",
         "8",
         "301.0",
         "335",
         "3.54",
         "3.57",
         "14.6",
         "0",
         "1",
         "5",
         "8"
        ],
        [
         "31",
         "Volvo 142E",
         "21.4",
         "4",
         "121.0",
         "109",
         "4.11",
         "2.78",
         "18.6",
         "1",
         "1",
         "4",
         "2"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 32
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mazda RX4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mazda RX4 Wag</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datsun 710</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hornet 4 Drive</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hornet Sportabout</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Valiant</td>\n",
       "      <td>18.1</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>105</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.460</td>\n",
       "      <td>20.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Duster 360</td>\n",
       "      <td>14.3</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>245</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.570</td>\n",
       "      <td>15.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Merc 240D</td>\n",
       "      <td>24.4</td>\n",
       "      <td>4</td>\n",
       "      <td>146.7</td>\n",
       "      <td>62</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.190</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Merc 230</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>140.8</td>\n",
       "      <td>95</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.150</td>\n",
       "      <td>22.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Merc 280</td>\n",
       "      <td>19.2</td>\n",
       "      <td>6</td>\n",
       "      <td>167.6</td>\n",
       "      <td>123</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.440</td>\n",
       "      <td>18.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Merc 280C</td>\n",
       "      <td>17.8</td>\n",
       "      <td>6</td>\n",
       "      <td>167.6</td>\n",
       "      <td>123</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.440</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Merc 450SE</td>\n",
       "      <td>16.4</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>4.070</td>\n",
       "      <td>17.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Merc 450SL</td>\n",
       "      <td>17.3</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.730</td>\n",
       "      <td>17.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Merc 450SLC</td>\n",
       "      <td>15.2</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.780</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cadillac Fleetwood</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "      <td>472.0</td>\n",
       "      <td>205</td>\n",
       "      <td>2.93</td>\n",
       "      <td>5.250</td>\n",
       "      <td>17.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lincoln Continental</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "      <td>460.0</td>\n",
       "      <td>215</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.424</td>\n",
       "      <td>17.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chrysler Imperial</td>\n",
       "      <td>14.7</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>230</td>\n",
       "      <td>3.23</td>\n",
       "      <td>5.345</td>\n",
       "      <td>17.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fiat 128</td>\n",
       "      <td>32.4</td>\n",
       "      <td>4</td>\n",
       "      <td>78.7</td>\n",
       "      <td>66</td>\n",
       "      <td>4.08</td>\n",
       "      <td>2.200</td>\n",
       "      <td>19.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Honda Civic</td>\n",
       "      <td>30.4</td>\n",
       "      <td>4</td>\n",
       "      <td>75.7</td>\n",
       "      <td>52</td>\n",
       "      <td>4.93</td>\n",
       "      <td>1.615</td>\n",
       "      <td>18.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Toyota Corolla</td>\n",
       "      <td>33.9</td>\n",
       "      <td>4</td>\n",
       "      <td>71.1</td>\n",
       "      <td>65</td>\n",
       "      <td>4.22</td>\n",
       "      <td>1.835</td>\n",
       "      <td>19.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Toyota Corona</td>\n",
       "      <td>21.5</td>\n",
       "      <td>4</td>\n",
       "      <td>120.1</td>\n",
       "      <td>97</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.465</td>\n",
       "      <td>20.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dodge Challenger</td>\n",
       "      <td>15.5</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.520</td>\n",
       "      <td>16.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AMC Javelin</td>\n",
       "      <td>15.2</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.435</td>\n",
       "      <td>17.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Camaro Z28</td>\n",
       "      <td>13.3</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>245</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.840</td>\n",
       "      <td>15.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pontiac Firebird</td>\n",
       "      <td>19.2</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.845</td>\n",
       "      <td>17.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Fiat X1-9</td>\n",
       "      <td>27.3</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>66</td>\n",
       "      <td>4.08</td>\n",
       "      <td>1.935</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Porsche 914-2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.3</td>\n",
       "      <td>91</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.140</td>\n",
       "      <td>16.70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lotus Europa</td>\n",
       "      <td>30.4</td>\n",
       "      <td>4</td>\n",
       "      <td>95.1</td>\n",
       "      <td>113</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.513</td>\n",
       "      <td>16.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Ford Pantera L</td>\n",
       "      <td>15.8</td>\n",
       "      <td>8</td>\n",
       "      <td>351.0</td>\n",
       "      <td>264</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.170</td>\n",
       "      <td>14.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ferrari Dino</td>\n",
       "      <td>19.7</td>\n",
       "      <td>6</td>\n",
       "      <td>145.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.770</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Maserati Bora</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>301.0</td>\n",
       "      <td>335</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.570</td>\n",
       "      <td>14.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Volvo 142E</td>\n",
       "      <td>21.4</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>109</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.780</td>\n",
       "      <td>18.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  \\\n",
       "0             Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1   \n",
       "1         Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1   \n",
       "2            Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1   \n",
       "3        Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0   \n",
       "4     Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0   \n",
       "5               Valiant  18.1    6  225.0  105  2.76  3.460  20.22   1   0   \n",
       "6            Duster 360  14.3    8  360.0  245  3.21  3.570  15.84   0   0   \n",
       "7             Merc 240D  24.4    4  146.7   62  3.69  3.190  20.00   1   0   \n",
       "8              Merc 230  22.8    4  140.8   95  3.92  3.150  22.90   1   0   \n",
       "9              Merc 280  19.2    6  167.6  123  3.92  3.440  18.30   1   0   \n",
       "10            Merc 280C  17.8    6  167.6  123  3.92  3.440  18.90   1   0   \n",
       "11           Merc 450SE  16.4    8  275.8  180  3.07  4.070  17.40   0   0   \n",
       "12           Merc 450SL  17.3    8  275.8  180  3.07  3.730  17.60   0   0   \n",
       "13          Merc 450SLC  15.2    8  275.8  180  3.07  3.780  18.00   0   0   \n",
       "14   Cadillac Fleetwood  10.4    8  472.0  205  2.93  5.250  17.98   0   0   \n",
       "15  Lincoln Continental  10.4    8  460.0  215  3.00  5.424  17.82   0   0   \n",
       "16    Chrysler Imperial  14.7    8  440.0  230  3.23  5.345  17.42   0   0   \n",
       "17             Fiat 128  32.4    4   78.7   66  4.08  2.200  19.47   1   1   \n",
       "18          Honda Civic  30.4    4   75.7   52  4.93  1.615  18.52   1   1   \n",
       "19       Toyota Corolla  33.9    4   71.1   65  4.22  1.835  19.90   1   1   \n",
       "20        Toyota Corona  21.5    4  120.1   97  3.70  2.465  20.01   1   0   \n",
       "21     Dodge Challenger  15.5    8  318.0  150  2.76  3.520  16.87   0   0   \n",
       "22          AMC Javelin  15.2    8  304.0  150  3.15  3.435  17.30   0   0   \n",
       "23           Camaro Z28  13.3    8  350.0  245  3.73  3.840  15.41   0   0   \n",
       "24     Pontiac Firebird  19.2    8  400.0  175  3.08  3.845  17.05   0   0   \n",
       "25            Fiat X1-9  27.3    4   79.0   66  4.08  1.935  18.90   1   1   \n",
       "26        Porsche 914-2  26.0    4  120.3   91  4.43  2.140  16.70   0   1   \n",
       "27         Lotus Europa  30.4    4   95.1  113  3.77  1.513  16.90   1   1   \n",
       "28       Ford Pantera L  15.8    8  351.0  264  4.22  3.170  14.50   0   1   \n",
       "29         Ferrari Dino  19.7    6  145.0  175  3.62  2.770  15.50   0   1   \n",
       "30        Maserati Bora  15.0    8  301.0  335  3.54  3.570  14.60   0   1   \n",
       "31           Volvo 142E  21.4    4  121.0  109  4.11  2.780  18.60   1   1   \n",
       "\n",
       "    gear  carb  \n",
       "0      4     4  \n",
       "1      4     4  \n",
       "2      4     1  \n",
       "3      3     1  \n",
       "4      3     2  \n",
       "5      3     1  \n",
       "6      3     4  \n",
       "7      4     2  \n",
       "8      4     2  \n",
       "9      4     4  \n",
       "10     4     4  \n",
       "11     3     3  \n",
       "12     3     3  \n",
       "13     3     3  \n",
       "14     3     4  \n",
       "15     3     4  \n",
       "16     3     4  \n",
       "17     4     1  \n",
       "18     4     2  \n",
       "19     4     1  \n",
       "20     3     1  \n",
       "21     3     2  \n",
       "22     3     2  \n",
       "23     3     4  \n",
       "24     3     2  \n",
       "25     4     1  \n",
       "26     5     2  \n",
       "27     5     2  \n",
       "28     5     4  \n",
       "29     5     6  \n",
       "30     5     8  \n",
       "31     4     2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = pd.read_csv('data/mtcars.csv')\n",
    "cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet performs a multiple linear regression analysis using the `statsmodels` library. It dynamically constructs a regression formula based on the columns of the `cars` DataFrame and fits an Ordinary Least Squares (OLS) model to predict the `mpg` (miles per gallon) variable.\n",
    "\n",
    "### Step-by-Step Explanation:\n",
    "\n",
    "1. **Constructing the Formula**:\n",
    "   - `cars.columns.drop(['model', 'mpg'])`:\n",
    "     - This retrieves all column names from the `cars` DataFrame, excluding the `model` and `mpg` columns. The `drop` method removes these specified columns from the list of column names.\n",
    "     - The `model` column is likely excluded because it contains non-numeric or categorical data (e.g., car names), which cannot be directly used in regression. The `mpg` column is excluded because it is the dependent variable (target) being predicted.\n",
    "\n",
    "   - `'+'.join(...)`:\n",
    "     - The remaining column names are joined into a single string, separated by the `+` symbol. This creates the right-hand side of the regression formula, where each column is treated as an independent variable (predictor).\n",
    "     - For example, if the remaining columns are `wt`, `hp`, and `qsec`, the resulting string would be `'wt+hp+qsec'`.\n",
    "\n",
    "   - `'mpg ~' + all_cols`:\n",
    "     - The formula string is constructed by concatenating `'mpg ~'` (indicating that `mpg` is the dependent variable) with the string of independent variables (`all_cols`). The final formula might look like `'mpg ~ wt+hp+qsec'`.\n",
    "\n",
    "2. **Fitting the OLS Model**:\n",
    "   - `smf.ols('mpg ~' + all_cols, data=cars)`:\n",
    "     - The `ols` function from `statsmodels.formula.api` is used to define an Ordinary Least Squares (OLS) regression model. The formula specifies the relationship between the dependent variable (`mpg`) and the independent variables (all other columns except `model` and `mpg`).\n",
    "     - The `data=cars` argument specifies that the variables in the formula are columns in the `cars` DataFrame.\n",
    "\n",
    "   - `.fit()`:\n",
    "     - The `fit` method solves the regression equation by estimating the coefficients for each independent variable. It uses numerical techniques (e.g., the Moore-Penrose pseudoinverse or QR decomposition) to minimize the residual sum of squares between the observed and predicted values of `mpg`.\n",
    "\n",
    "3. **Displaying the Summary**:\n",
    "   - `.summary()`:\n",
    "     - This generates a detailed summary of the fitted regression model. The summary includes:\n",
    "       - **Coefficients**: The estimated values for each independent variable, indicating their contribution to predicting `mpg`.\n",
    "       - **P-values**: Statistical significance of each coefficient, showing whether the variable has a meaningful relationship with `mpg`.\n",
    "       - **R-squared**: A measure of how well the independent variables explain the variability in `mpg`.\n",
    "       - **F-statistic**: A test for the overall significance of the model.\n",
    "       - **Residual Statistics**: Information about the distribution of the model's errors.\n",
    "\n",
    "### Purpose:\n",
    "This code automates the process of constructing a regression formula and fitting a model to predict `mpg` based on all relevant predictors in the dataset. By dynamically generating the formula, it ensures flexibility and scalability, especially when working with datasets that have many columns. The resulting summary provides insights into the relationships between the predictors and the target variable, helping to evaluate the model's performance and identify significant predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.869</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   13.93</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 May 2025</td> <th>  Prob (F-statistic):</th> <td>3.79e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:34:22</td>     <th>  Log-Likelihood:    </th> <td> -69.855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   161.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   177.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   12.3034</td> <td>   18.718</td> <td>    0.657</td> <td> 0.518</td> <td>  -26.623</td> <td>   51.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cyl</th>       <td>   -0.1114</td> <td>    1.045</td> <td>   -0.107</td> <td> 0.916</td> <td>   -2.285</td> <td>    2.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>disp</th>      <td>    0.0133</td> <td>    0.018</td> <td>    0.747</td> <td> 0.463</td> <td>   -0.024</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hp</th>        <td>   -0.0215</td> <td>    0.022</td> <td>   -0.987</td> <td> 0.335</td> <td>   -0.067</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>drat</th>      <td>    0.7871</td> <td>    1.635</td> <td>    0.481</td> <td> 0.635</td> <td>   -2.614</td> <td>    4.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wt</th>        <td>   -3.7153</td> <td>    1.894</td> <td>   -1.961</td> <td> 0.063</td> <td>   -7.655</td> <td>    0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qsec</th>      <td>    0.8210</td> <td>    0.731</td> <td>    1.123</td> <td> 0.274</td> <td>   -0.699</td> <td>    2.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vs</th>        <td>    0.3178</td> <td>    2.105</td> <td>    0.151</td> <td> 0.881</td> <td>   -4.059</td> <td>    4.694</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>am</th>        <td>    2.5202</td> <td>    2.057</td> <td>    1.225</td> <td> 0.234</td> <td>   -1.757</td> <td>    6.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gear</th>      <td>    0.6554</td> <td>    1.493</td> <td>    0.439</td> <td> 0.665</td> <td>   -2.450</td> <td>    3.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carb</th>      <td>   -0.1994</td> <td>    0.829</td> <td>   -0.241</td> <td> 0.812</td> <td>   -1.923</td> <td>    1.524</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.907</td> <th>  Durbin-Watson:     </th> <td>   1.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.385</td> <th>  Jarque-Bera (JB):  </th> <td>   1.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.521</td> <th>  Prob(JB):          </th> <td>   0.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.526</td> <th>  Cond. No.          </th> <td>1.22e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.22e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       mpg        & \\textbf{  R-squared:         } &     0.869   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.807   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     13.93   \\\\\n",
       "\\textbf{Date:}             & Mon, 12 May 2025 & \\textbf{  Prob (F-statistic):} &  3.79e-07   \\\\\n",
       "\\textbf{Time:}             &     19:34:22     & \\textbf{  Log-Likelihood:    } &   -69.855   \\\\\n",
       "\\textbf{No. Observations:} &          32      & \\textbf{  AIC:               } &     161.7   \\\\\n",
       "\\textbf{Df Residuals:}     &          21      & \\textbf{  BIC:               } &     177.8   \\\\\n",
       "\\textbf{Df Model:}         &          10      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      12.3034  &       18.718     &     0.657  &         0.518        &      -26.623    &       51.229     \\\\\n",
       "\\textbf{cyl}       &      -0.1114  &        1.045     &    -0.107  &         0.916        &       -2.285    &        2.062     \\\\\n",
       "\\textbf{disp}      &       0.0133  &        0.018     &     0.747  &         0.463        &       -0.024    &        0.050     \\\\\n",
       "\\textbf{hp}        &      -0.0215  &        0.022     &    -0.987  &         0.335        &       -0.067    &        0.024     \\\\\n",
       "\\textbf{drat}      &       0.7871  &        1.635     &     0.481  &         0.635        &       -2.614    &        4.188     \\\\\n",
       "\\textbf{wt}        &      -3.7153  &        1.894     &    -1.961  &         0.063        &       -7.655    &        0.224     \\\\\n",
       "\\textbf{qsec}      &       0.8210  &        0.731     &     1.123  &         0.274        &       -0.699    &        2.341     \\\\\n",
       "\\textbf{vs}        &       0.3178  &        2.105     &     0.151  &         0.881        &       -4.059    &        4.694     \\\\\n",
       "\\textbf{am}        &       2.5202  &        2.057     &     1.225  &         0.234        &       -1.757    &        6.797     \\\\\n",
       "\\textbf{gear}      &       0.6554  &        1.493     &     0.439  &         0.665        &       -2.450    &        3.761     \\\\\n",
       "\\textbf{carb}      &      -0.1994  &        0.829     &    -0.241  &         0.812        &       -1.923    &        1.524     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.907 & \\textbf{  Durbin-Watson:     } &    1.861  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.385 & \\textbf{  Jarque-Bera (JB):  } &    1.747  \\\\\n",
       "\\textbf{Skew:}          &  0.521 & \\textbf{  Prob(JB):          } &    0.418  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.526 & \\textbf{  Cond. No.          } & 1.22e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.22e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.869\n",
       "Model:                            OLS   Adj. R-squared:                  0.807\n",
       "Method:                 Least Squares   F-statistic:                     13.93\n",
       "Date:                Mon, 12 May 2025   Prob (F-statistic):           3.79e-07\n",
       "Time:                        19:34:22   Log-Likelihood:                -69.855\n",
       "No. Observations:                  32   AIC:                             161.7\n",
       "Df Residuals:                      21   BIC:                             177.8\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     12.3034     18.718      0.657      0.518     -26.623      51.229\n",
       "cyl           -0.1114      1.045     -0.107      0.916      -2.285       2.062\n",
       "disp           0.0133      0.018      0.747      0.463      -0.024       0.050\n",
       "hp            -0.0215      0.022     -0.987      0.335      -0.067       0.024\n",
       "drat           0.7871      1.635      0.481      0.635      -2.614       4.188\n",
       "wt            -3.7153      1.894     -1.961      0.063      -7.655       0.224\n",
       "qsec           0.8210      0.731      1.123      0.274      -0.699       2.341\n",
       "vs             0.3178      2.105      0.151      0.881      -4.059       4.694\n",
       "am             2.5202      2.057      1.225      0.234      -1.757       6.797\n",
       "gear           0.6554      1.493      0.439      0.665      -2.450       3.761\n",
       "carb          -0.1994      0.829     -0.241      0.812      -1.923       1.524\n",
       "==============================================================================\n",
       "Omnibus:                        1.907   Durbin-Watson:                   1.861\n",
       "Prob(Omnibus):                  0.385   Jarque-Bera (JB):                1.747\n",
       "Skew:                           0.521   Prob(JB):                        0.418\n",
       "Kurtosis:                       2.526   Cond. No.                     1.22e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.22e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols = '+'.join(cars.columns.drop(['model', 'mpg']))\n",
    "smf.ols('mpg ~' + all_cols, data=cars).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recursive Feature Elimination (RFE)** will first fit a model with all available variables and then look at the resulting coefficients. It will discard the variable with the smallest absolute coefficient (the one most close to 0) and then will fit a new model on the remaining variables. This process will be repeated until only a pre-specified number of variables remains.\n",
    "\n",
    "This is more robust than just selecting the variables with the best coefficients, since the values of the coefficients can be affected in case some variables are correlated. Removing variables one by one decreases the chances of discarding meaningful variables or keeping uninformative ones.\n",
    "\n",
    "This code snippet demonstrates the use of Recursive Feature Elimination (RFE) with a linear regression model to select the most important features for predicting the target variable `mpg` (miles per gallon) from the `cars` dataset.\n",
    "\n",
    "### Step-by-Step Explanation:\n",
    "\n",
    "1. **Defining the Features (`X`) and Target (`y`)**:\n",
    "   - `X = cars.iloc[:, 2:]`:\n",
    "     - This selects all columns of the `cars` DataFrame starting from the third column onward (index 2) as the feature set. These columns represent the independent variables (predictors) used to predict the target variable.\n",
    "   - `y = cars['mpg']`:\n",
    "     - This selects the `mpg` column from the `cars` DataFrame as the target variable. The goal is to predict `mpg` using the selected features.\n",
    "\n",
    "2. **Initializing the Linear Regression Model**:\n",
    "   - `lr = LinearRegression()`:\n",
    "     - An instance of the `LinearRegression` class from Scikit-learn is created. This model will be used as the base estimator for RFE. Linear regression fits a linear model to the data by minimizing the residual sum of squares between the observed and predicted values.\n",
    "\n",
    "3. **Applying Recursive Feature Elimination (RFE)**:\n",
    "   - `RFE(lr, n_features_to_select=3)`:\n",
    "     - RFE is initialized with the linear regression model (`lr`) as the base estimator and the number of features to select (`n_features_to_select=3`). RFE works by recursively removing the least important features based on the model's coefficients until the specified number of features remains.\n",
    "     - The importance of each feature is determined by the magnitude of its coefficient in the linear regression model. Features with smaller absolute coefficients are considered less important and are removed first.\n",
    "\n",
    "4. **Fitting the RFE Model**:\n",
    "   - `.fit(X, y)`:\n",
    "     - The RFE model is fitted to the feature set `X` and the target variable `y`. During this process:\n",
    "       - The linear regression model is trained on the current set of features.\n",
    "       - The least important features are identified and removed.\n",
    "       - This process is repeated until only the top 3 features remain.\n",
    "\n",
    "### Purpose:\n",
    "This code is used to identify the three most important features in the dataset for predicting `mpg`. By reducing the number of features, RFE helps simplify the model, improve interpretability, and potentially enhance performance by removing irrelevant or redundant predictors. The selected features can then be used for further analysis or model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X   = cars.iloc[:, 2:]\n",
    "y   = cars['mpg']\n",
    "lr  = LinearRegression()\n",
    "rfe = RFE(lr, n_features_to_select=3).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet outputs the results of the Recursive Feature Elimination (RFE) process, which was applied earlier to select the most important features for predicting the target variable `mpg` (miles per gallon). The `print` statements display two key attributes of the fitted RFE model: `support_` and `ranking_`.\n",
    "\n",
    "### Explanation of Outputs:\n",
    "\n",
    "1. **`rfe.support_`**:\n",
    "   - The `support_` attribute is a Boolean array where each element corresponds to a feature in the dataset. A value of `True` indicates that the feature was selected as one of the most important features by the RFE process, while `False` indicates that the feature was not selected.\n",
    "   - For example, if there are 10 features in the dataset and the RFE process was configured to select 3 features, the `support_` array will contain exactly three `True` values, corresponding to the selected features.\n",
    "\n",
    "2. **`rfe.ranking_`**:\n",
    "   - The `ranking_` attribute is an array of integers where each element corresponds to a feature in the dataset. The ranking indicates the relative importance of each feature, with a rank of `1` assigned to the selected features (the most important ones). Higher numbers indicate less important features, with the least important feature receiving the highest rank.\n",
    "   - For example, if there are 10 features and 3 were selected, the selected features will have a rank of `1`, while the remaining features will have ranks greater than `1`.\n",
    "\n",
    "### Purpose:\n",
    "These outputs provide insight into the feature selection process performed by RFE. The `support_` array identifies which features were chosen, while the `ranking_` array provides a complete ranking of all features based on their importance. This information is useful for understanding the decisions made by the RFE algorithm and for interpreting the results of the feature selection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support : [False False False False  True  True False  True False False]\n",
      "Ranking : [6 8 7 2 1 1 5 1 4 3]\n"
     ]
    }
   ],
   "source": [
    "print('Support :', rfe.support_)\n",
    "print('Ranking :', rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet identifies and orders the feature names in the `cars` dataset based on their importance as determined by the Recursive Feature Elimination (RFE) process. Here's a detailed explanation:\n",
    "\n",
    "### Step-by-Step Explanation:\n",
    "\n",
    "1. **Selecting Feature Columns**:\n",
    "   - `cars.columns[2:]`:\n",
    "     - This retrieves the column names of the `cars` DataFrame starting from the third column onward (index 2). These columns represent the independent variables (features) used in the RFE process.\n",
    "\n",
    "2. **Accessing RFE Rankings**:\n",
    "   - `rfe.ranking_`:\n",
    "     - The `ranking_` attribute of the fitted RFE object contains the ranking of each feature. Features with a rank of `1` are the most important (selected by RFE), while higher ranks indicate less important features.\n",
    "\n",
    "3. **Adjusting Rankings**:\n",
    "   - `rfe.ranking_ - 1`:\n",
    "     - This subtracts `1` from each rank, effectively converting the most important features (rank `1`) to `0`. This adjustment is useful for sorting purposes, as lower values indicate higher importance.\n",
    "\n",
    "4. **Sorting Feature Indices**:\n",
    "   - `np.argsort(rfe.ranking_ - 1)`:\n",
    "     - The `np.argsort` function returns the indices that would sort the adjusted rankings in ascending order. This means the most important features (with the lowest adjusted rank) will appear first in the sorted order.\n",
    "\n",
    "5. **Mapping Indices to Feature Names**:\n",
    "   - `cars.columns[2:][...]`:\n",
    "     - The sorted indices are used to reorder the feature names from `cars.columns[2:]`. This results in a list of feature names sorted by their importance, with the most important features appearing first.\n",
    "\n",
    "### Purpose:\n",
    "This code provides a clear, ordered list of feature names based on their importance as determined by RFE. It is particularly useful for interpreting the results of the feature selection process, as it highlights which features contribute the most to the predictive model. This ordered list can guide further analysis or model refinement by focusing on the most relevant predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['wt', 'qsec', 'am', 'drat', 'carb', 'gear', 'vs', 'cyl', 'hp', 'disp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(cars.columns[2:][np.argsort(rfe.ranking_ - 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet fits a linear regression model using only the features selected by Recursive Feature Elimination (RFE) and then prints key metrics of the resulting model.\n",
    "\n",
    "First, `X = rfe.fit_transform(X, y)` applies the RFE process to the feature matrix `X` and target vector `y`. This step both fits the RFE selector and transforms `X` to retain only the most important features (as determined by RFE). The resulting `X` now contains only the subset of features chosen as most predictive for `mpg`.\n",
    "\n",
    "Next, `y = cars['mpg']` ensures that the target variable is set to the `mpg` column from the original `cars` DataFrame. This is necessary because the transformed `X` may be used in further modeling steps, and you want to make sure `y` is aligned with the original data.\n",
    "\n",
    "Then, `lr_rfe = LinearRegression().fit(X, y)` creates a new instance of the `LinearRegression` class and fits it to the reduced feature set and the target variable. This step trains the linear regression model using only the features selected by RFE.\n",
    "\n",
    "Finally, the code prints out three important pieces of information about the fitted model:\n",
    "- The intercept (`lr_rfe.intercept_`), which is the baseline value of `mpg` when all selected features are zero.\n",
    "- The coefficients (`lr_rfe.coef_`), which represent the estimated effect of each selected feature on `mpg`.\n",
    "- The RÂ² score (`lr_rfe.score(X, y)`), which indicates how well the model explains the variance in `mpg` using the selected features (with 1.0 being a perfect fit and 0.0 meaning no explanatory power).\n",
    "\n",
    "This workflow is useful for evaluating how well a linear regression model performs when using only the most relevant features, as determined by RFE, rather than all available predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept   : 9.617780514561607\n",
      "Coefficients: [-3.91650372  1.22588597  2.93583719]\n",
      "R^2         : 0.8496635563617072\n"
     ]
    }
   ],
   "source": [
    "X      = rfe.fit_transform(X, y)\n",
    "y      = cars['mpg']\n",
    "lr_rfe = LinearRegression().fit(X, y)\n",
    "print('Intercept   :', lr_rfe.intercept_)\n",
    "print('Coefficients:', lr_rfe.coef_)\n",
    "print('R^2         :', lr_rfe.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet performs a multiple linear regression analysis using the `statsmodels` library to model the relationship between the dependent variable `mpg` (miles per gallon) and three independent variables: `wt` (weight), `qsec` (1/4 mile time), and `am` (transmission type). Here's a detailed explanation:\n",
    "\n",
    "### Step-by-Step Explanation:\n",
    "\n",
    "1. **Defining the Model**:\n",
    "   - `smf.ols('mpg ~ wt + qsec + am', data=cars)`:\n",
    "     - The `ols` function from `statsmodels.formula.api` is used to define an Ordinary Least Squares (OLS) regression model.\n",
    "     - The formula `'mpg ~ wt + qsec + am'` specifies that `mpg` is the dependent variable, while `wt`, `qsec`, and `am` are the independent variables (predictors).\n",
    "     - The `data=cars` argument indicates that the variables in the formula are columns in the `cars` DataFrame.\n",
    "\n",
    "2. **Fitting the Model**:\n",
    "   - `.fit()`:\n",
    "     - The `fit` method estimates the coefficients of the regression model by solving the least squares minimization problem. This involves finding the values of the coefficients that minimize the sum of squared residuals (differences between observed and predicted values of `mpg`).\n",
    "     - Depending on the method used (e.g., Moore-Penrose pseudoinverse or QR decomposition), the model calculates the coefficients and other statistics.\n",
    "\n",
    "3. **Generating the Summary**:\n",
    "   - `.summary()`:\n",
    "     - This generates a detailed summary of the fitted regression model. The summary includes:\n",
    "       - **Coefficients**: The estimated values for each independent variable, indicating their contribution to predicting `mpg`.\n",
    "       - **P-values**: Statistical significance of each coefficient, showing whether the variable has a meaningful relationship with `mpg`.\n",
    "       - **R-squared**: A measure of how well the independent variables explain the variability in `mpg`. Higher values indicate a better fit.\n",
    "       - **F-statistic**: A test for the overall significance of the model, indicating whether the independent variables collectively explain a significant portion of the variability in `mpg`.\n",
    "       - **Residual Statistics**: Information about the distribution of the model's errors, such as standard error and confidence intervals.\n",
    "\n",
    "### Purpose:\n",
    "This code is used to evaluate the relationship between `mpg` and the selected predictors (`wt`, `qsec`, and `am`). By examining the summary, you can determine which variables significantly influence `mpg`, assess the overall fit of the model, and interpret the direction and magnitude of the relationships. This type of analysis is commonly used in data science and statistics to understand and quantify relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   52.75</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 May 2025</td> <th>  Prob (F-statistic):</th> <td>1.21e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:34:22</td>     <th>  Log-Likelihood:    </th> <td> -72.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   152.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    28</td>      <th>  BIC:               </th> <td>   158.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    9.6178</td> <td>    6.960</td> <td>    1.382</td> <td> 0.178</td> <td>   -4.638</td> <td>   23.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wt</th>        <td>   -3.9165</td> <td>    0.711</td> <td>   -5.507</td> <td> 0.000</td> <td>   -5.373</td> <td>   -2.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qsec</th>      <td>    1.2259</td> <td>    0.289</td> <td>    4.247</td> <td> 0.000</td> <td>    0.635</td> <td>    1.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>am</th>        <td>    2.9358</td> <td>    1.411</td> <td>    2.081</td> <td> 0.047</td> <td>    0.046</td> <td>    5.826</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.574</td> <th>  Durbin-Watson:     </th> <td>   1.714</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.276</td> <th>  Jarque-Bera (JB):  </th> <td>   2.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.540</td> <th>  Prob(JB):          </th> <td>   0.331</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.297</td> <th>  Cond. No.          </th> <td>    296.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       mpg        & \\textbf{  R-squared:         } &     0.850   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.834   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     52.75   \\\\\n",
       "\\textbf{Date:}             & Mon, 12 May 2025 & \\textbf{  Prob (F-statistic):} &  1.21e-11   \\\\\n",
       "\\textbf{Time:}             &     19:34:22     & \\textbf{  Log-Likelihood:    } &   -72.060   \\\\\n",
       "\\textbf{No. Observations:} &          32      & \\textbf{  AIC:               } &     152.1   \\\\\n",
       "\\textbf{Df Residuals:}     &          28      & \\textbf{  BIC:               } &     158.0   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &       9.6178  &        6.960     &     1.382  &         0.178        &       -4.638    &       23.874     \\\\\n",
       "\\textbf{wt}        &      -3.9165  &        0.711     &    -5.507  &         0.000        &       -5.373    &       -2.460     \\\\\n",
       "\\textbf{qsec}      &       1.2259  &        0.289     &     4.247  &         0.000        &        0.635    &        1.817     \\\\\n",
       "\\textbf{am}        &       2.9358  &        1.411     &     2.081  &         0.047        &        0.046    &        5.826     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  2.574 & \\textbf{  Durbin-Watson:     } &    1.714  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.276 & \\textbf{  Jarque-Bera (JB):  } &    2.213  \\\\\n",
       "\\textbf{Skew:}          &  0.540 & \\textbf{  Prob(JB):          } &    0.331  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.297 & \\textbf{  Cond. No.          } &     296.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.850\n",
       "Model:                            OLS   Adj. R-squared:                  0.834\n",
       "Method:                 Least Squares   F-statistic:                     52.75\n",
       "Date:                Mon, 12 May 2025   Prob (F-statistic):           1.21e-11\n",
       "Time:                        19:34:22   Log-Likelihood:                -72.060\n",
       "No. Observations:                  32   AIC:                             152.1\n",
       "Df Residuals:                      28   BIC:                             158.0\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      9.6178      6.960      1.382      0.178      -4.638      23.874\n",
       "wt            -3.9165      0.711     -5.507      0.000      -5.373      -2.460\n",
       "qsec           1.2259      0.289      4.247      0.000       0.635       1.817\n",
       "am             2.9358      1.411      2.081      0.047       0.046       5.826\n",
       "==============================================================================\n",
       "Omnibus:                        2.574   Durbin-Watson:                   1.714\n",
       "Prob(Omnibus):                  0.276   Jarque-Bera (JB):                2.213\n",
       "Skew:                           0.540   Prob(JB):                        0.331\n",
       "Kurtosis:                       2.297   Cond. No.                         296.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('mpg ~ wt + qsec + am', data=cars).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying PCA\n",
    "This code snippet prepares the data for Principal Component Analysis (PCA) by first standardizing the features and then fitting the PCA model.\n",
    "\n",
    "In the first line, `cars_norm = StandardScaler().fit_transform(cars.iloc[:, 2:])`, the code selects all columns from the `cars` DataFrame starting from the third column onward (using `cars.iloc[:, 2:]`). These columns represent the numerical features to be analyzed. The `StandardScaler` is then used to standardize these features, which means each feature is transformed to have a mean of zero and a standard deviation of one. Standardization is important for PCA because it ensures that all features contribute equally to the analysis, regardless of their original scale or units.\n",
    "\n",
    "In the second line, `pca = PCA().fit(cars_norm)`, the code creates a new PCA object and fits it to the standardized data. Fitting the PCA model involves finding the directions (principal components) in the data that capture the most variance. These principal components can then be used for dimensionality reduction, visualization, or further analysis. By standardizing the data before applying PCA, the results are not biased toward features with larger variances or different units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA component 0 cumulative explained variance:    0.57602174356957214219\n",
      "PCA component 1 cumulative explained variance:    0.84098606227748717856\n",
      "PCA component 2 cumulative explained variance:    0.90070754778627926118\n",
      "PCA component 3 cumulative explained variance:    0.92765821517457291989\n",
      "PCA component 4 cumulative explained variance:    0.94988322156637294835\n",
      "PCA component 5 cumulative explained variance:    0.97089496522694651581\n",
      "PCA component 6 cumulative explained variance:    0.98418697420373491003\n",
      "PCA component 7 cumulative explained variance:    0.99225513222446493078\n",
      "PCA component 8 cumulative explained variance:    0.99762036701418599360\n",
      "PCA component 9 cumulative explained variance:    1.00000000000000000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cars_norm = StandardScaler().fit_transform(cars.iloc[:, 2:])\n",
    "pca = PCA().fit(cars_norm)\n",
    "for i in range(len(pca.components_)):\n",
    "    print('PCA component %d cumulative explained variance: %25.20f' % (i, np.sum(pca.explained_variance_ratio_[:i+1])))\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance') \n",
    "plt.title('PCA: Explained variance ratio')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a side-by-side visualization to help interpret the results of Principal Component Analysis (PCA). The first line, `fig, ax = plt.subplots(1, 2, figsize=(12, 6))`, sets up a figure with two subplots arranged in one row and two columns, and specifies the overall figure size.\n",
    "\n",
    "In the first subplot (`ax[0]`), a bar chart is drawn showing the proportion of variance explained by each of the first 10 principal components. The x-axis represents the principal component number (from 1 to 10), and the y-axis shows how much variance each component explains individually, using `pca.explained_variance_ratio_`.\n",
    "\n",
    "In the second subplot (`ax[1]`), another bar chart is plotted, but this time it shows the cumulative sum of the explained variance ratios. This helps visualize how much total variance is captured as more principal components are included.\n",
    "\n",
    "The axis labels are set to clarify what each subplot represents: the first shows \"Proportion of explained variance\" for each component, and the second shows \"Proportion of retained variance\" as components are accumulated. `plt.tight_layout()` adjusts the spacing to prevent overlap between subplots, and `plt.show()` displays the figure.\n",
    "\n",
    "Overall, this visualization helps you quickly assess how many principal components are needed to capture most of the variance in the dataset, which is useful for dimensionality reduction decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJNCAYAAADgesaeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXkFJREFUeJzt3XlcVXXi//H3FQTcwB0lkWXUUnELWsTU3HDMMS2/qWlqqY2E5oJLkpVKKmpFjCkuU6amGZnW5GgZY7lnJootmpVLGEKklriFCff3hz/vzA0ojl3OYXk9H4/zeHA/95xz31cezXweb875HJvdbrcLAAAAAAAAMFEFqwMAAAAAAACg/KGUAgAAAAAAgOkopQAAAAAAAGA6SikAAAAAAACYjlIKAAAAAAAApqOUAgAAAAAAgOkopQAAAAAAAGA6SikAAAAAAACYjlIKAAAAAAAApnO3OoDZ8vLydOrUKVWrVk02m83qOAAAoISz2+06f/68/Pz8VKFC+f17HnMoAABQVEWdP1leSiUmJuq5555TRkaGmjdvroSEBLVv377Q/XNychQbG6tVq1YpMzNTDRo00NSpUzVs2LAifd6pU6fk7+/vqvgAAKCcOHnypBo0aGB1DMswhwIAAEb90fzJ0lIqKSlJ48aNU2Jiotq1a6clS5aoR48eOnTokBo2bFjgMf369dMPP/ygV155RY0aNVJWVpauXr1a5M+sVq2apGv/MN7e3i75HgAAoOzKzs6Wv7+/Yw5RXjGHAgAARVXU+ZPNbrfbTcqUzx133KFbb71VixYtcow1bdpUffr0UVxcXL7933//fQ0YMEDHjh1TzZo1b+gzs7Oz5ePjo3PnzjGhAgAAf4i5wzX8OwAAgKIq6rzBsoURrly5opSUFEVERDiNR0REaPfu3QUe8+677yosLEzz5s3TTTfdpCZNmmjixIm6fPlyoZ+Tk5Oj7Oxspw0AAAAAAADWsuz2vdOnTys3N1e+vr5O476+vsrMzCzwmGPHjmnnzp3y8vLS22+/rdOnTysqKkpnz57VsmXLCjwmLi5OM2bMcHl+AAAAAAAA3DjLHyHz26e32O32Qp/okpeXJ5vNptWrV+v222/XPffco/j4eC1fvrzQq6ViYmJ07tw5x3by5EmXfwcAAAAAAAAYY9mVUrVr15abm1u+q6KysrLyXT11Xf369XXTTTfJx8fHMda0aVPZ7XZ9//33aty4cb5jPD095enp6drwAAAAAAAA+FMsu1LKw8NDoaGhSk5OdhpPTk5WeHh4gce0a9dOp06d0oULFxxjX3/9tSpUqFCuH9EMAAAAAABQ2lh6+150dLRefvllLVu2TIcPH9b48eOVlpamyMhISdduvRsyZIhj/4EDB6pWrVp65JFHdOjQIW3fvl2TJk3SsGHDVKlSJau+BgAAAAAAAAyy7PY9Serfv7/OnDmj2NhYZWRkKCQkRJs2bVJAQIAkKSMjQ2lpaY79q1atquTkZD3++OMKCwtTrVq11K9fP82cOdOqrwAAAAAAAIAbYLPb7XarQ5gpOztbPj4+OnfunLy9va2OAwAASjjmDtfw7wAAAIqqqPMGy5++BwAAAAAAgPKHUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAoZbZv365evXrJz89PNptN77zzzh8es23bNoWGhsrLy0vBwcFavHhx8QcFAAD4HZRSAAAApczFixfVqlUrLViwoEj7Hz9+XPfcc4/at2+vAwcO6Mknn9SYMWO0bt26Yk4KAABQOHerAwAAAMCYHj16qEePHkXef/HixWrYsKESEhIkSU2bNtW+ffv0/PPPq2/fvsWUEgAA4PdxpRQAAEAZ9/HHHysiIsJprHv37tq3b59+/fXXAo/JyclRdna20wYAAOBKXClVDAKnbLQ6QqFOzOlpdQQAAGCyzMxM+fr6Oo35+vrq6tWrOn36tOrXr5/vmLi4OM2YMcOsiAAAlEn0A7+PUgoAAKAcsNlsTq/tdnuB49fFxMQoOjra8To7O1v+/v7FFxAAgN+g0Cn7KKUAAADKuHr16ikzM9NpLCsrS+7u7qpVq1aBx3h6esrT09OMeAAAoJxiTSkAAIAyrm3btkpOTnYa++CDDxQWFqaKFStalAoAAJR3XCkFAABQyly4cEHffvut4/Xx48eVmpqqmjVrqmHDhoqJiVF6erpWrlwpSYqMjNSCBQsUHR2tRx99VB9//LFeeeUVrVmzxqqvAAAoZtz6htKAUgoAAKCU2bdvnzp16uR4fX3tp6FDh2r58uXKyMhQWlqa4/2goCBt2rRJ48eP18KFC+Xn56f58+erb9++pmcHAAC4jlIKAACglLn77rsdC5UXZPny5fnGOnbsqP379xdjKgAAAGNYUwoAAAAAAACm40opAAAAAAB+gzWZgOLHlVIAAAAAAAAwHaUUAAAAAAAATEcpBQAAAAAAANNRSgEAAAAAAMB0lFIAAAAAAAAwHU/fAwAAAAC4FE+uA1AUXCkFAAAAAAAA01FKAQAAAAAAwHSUUgAAAAAAADAdpRQAAAAAAABMRykFAAAAAAAA01FKAQAAAAAAwHSUUgAAAAAAADAdpRQAAAAAAABMRykFAAAAAAAA01FKAQAAAAAAwHTuVgcAAAAAAPxX4JSNVkco1Ik5Pa2OAKAM4UopAAAAAAAAmI5SCgAAAAAAAKajlAIAAAAAAIDpKKUAAAAAAABgOkopAAAAAAAAmI5SCgAAAAAAAKajlAIAAAAAAIDpKKUAAAAAAABgOkopAAAAAAAAmI5SCgAAAAAAAKZztzoAAAAAALhK4JSNVkco1Ik5Pa2OAAAlCldKAQAAAAAAwHSUUgAAAAAAADAdpRQAAAAAAABMRykFAAAAAAAA01FKAQAAAAAAwHSUUgAAAAAAADAdpRQAAAAAAABMRykFAAAAAAAA01FKAQAAAAAAwHSUUgAAAAAAADAdpRQAAAAAAABMRykFAAAAAAAA07lbHQAAAABAyRA4ZaPVEQp1Yk5PqyMAAFyMK6UAAAAAAABgOkopAAAAAAAAmI5SCgAAAAAAAKajlAIAAAAAAIDpKKUAAAAAAABgOkopAAAAAAAAmI5SCgAAAAAAAKajlAIAAAAAAIDpKKUAAAAAAABgOkopAAAAAAAAmI5SCgAAAAAAAKajlAIAAAAAAIDpLC+lEhMTFRQUJC8vL4WGhmrHjh2F7rt161bZbLZ821dffWViYgAAAAAAAPxZlpZSSUlJGjdunKZOnaoDBw6offv26tGjh9LS0n73uCNHjigjI8OxNW7c2KTEAAAAAAAAcAVLS6n4+HgNHz5cI0aMUNOmTZWQkCB/f38tWrTod4+rW7eu6tWr59jc3NxMSgwAAAAAAABXsKyUunLlilJSUhQREeE0HhERod27d//usW3atFH9+vXVpUsXffTRR7+7b05OjrKzs502AAAAAAAAWMuyUur06dPKzc2Vr6+v07ivr68yMzMLPKZ+/fpaunSp1q1bp/Xr1+vmm29Wly5dtH379kI/Jy4uTj4+Po7N39/fpd8DAAAAAAAAxrlbHcBmszm9ttvt+cauu/nmm3XzzTc7Xrdt21YnT57U888/rw4dOhR4TExMjKKjox2vs7OzKaYAAAAAAAAsZtmVUrVr15abm1u+q6KysrLyXT31e+6880598803hb7v6ekpb29vpw0AAAAAAADWsqyU8vDwUGhoqJKTk53Gk5OTFR4eXuTzHDhwQPXr13d1PAAAAAAAABQjS2/fi46O1uDBgxUWFqa2bdtq6dKlSktLU2RkpKRrt96lp6dr5cqVkqSEhAQFBgaqefPmunLlilatWqV169Zp3bp1Vn4NAAAAAAAAGGRpKdW/f3+dOXNGsbGxysjIUEhIiDZt2qSAgABJUkZGhtLS0hz7X7lyRRMnTlR6eroqVaqk5s2ba+PGjbrnnnus+goAAAAAAAC4AZYvdB4VFaWoqKgC31u+fLnT68mTJ2vy5MkmpAIAAAAAAEBxsmxNKQAAAAAAAJRflFIAAAAAAAAwHaUUAAAAAAAATEcpBQAAAAAAANNRSgEAAAAAAMB0lFIAAAAAAAAwnbvVAQAAAICyInDKRqsjFOrEnJ5WRwAAwAlXSgEAAAAAAMB0lFIAAAAAAAAwHaUUAAAAAAAATEcpBQAAAAAAANNRSgEAAAAAAMB0lFIAAAAAAAAwHaUUAAAAAAAATEcpBQAAAAAAANNRSgEAAAAAAMB0lFIAAAAAAAAwHaUUAAAAAAAATEcpBQAAAAAAANNRSgEAAAAAAMB0lFIAAAAAAAAwHaUUAAAAAAAATEcpBQAAAAAAANNRSgEAAJRCiYmJCgoKkpeXl0JDQ7Vjx47f3X/16tVq1aqVKleurPr16+uRRx7RmTNnTEoLAACQH6UUAABAKZOUlKRx48Zp6tSpOnDggNq3b68ePXooLS2twP137typIUOGaPjw4fryyy+1du1affrppxoxYoTJyQEAAP6LUgoAAKCUiY+P1/DhwzVixAg1bdpUCQkJ8vf316JFiwrcf8+ePQoMDNSYMWMUFBSku+66SyNHjtS+fftMTg4AAPBflFIAAAClyJUrV5SSkqKIiAin8YiICO3evbvAY8LDw/X9999r06ZNstvt+uGHH/TWW2+pZ8+ehX5OTk6OsrOznTYAAABXopQCAAAoRU6fPq3c3Fz5+vo6jfv6+iozM7PAY8LDw7V69Wr1799fHh4eqlevnqpXr66XXnqp0M+Ji4uTj4+PY/P393fp9wAAAKCUAgAAKIVsNpvTa7vdnm/sukOHDmnMmDF65plnlJKSovfff1/Hjx9XZGRkoeePiYnRuXPnHNvJkyddmh8AAMDd6gAAAAAoutq1a8vNzS3fVVFZWVn5rp66Li4uTu3atdOkSZMkSS1btlSVKlXUvn17zZw5U/Xr1893jKenpzw9PV3/BQAAAP4/rpQCAAAoRTw8PBQaGqrk5GSn8eTkZIWHhxd4zKVLl1ShgvO0z83NTdK1K6wAAACsQCkFAABQykRHR+vll1/WsmXLdPjwYY0fP15paWmO2/FiYmI0ZMgQx/69evXS+vXrtWjRIh07dky7du3SmDFjdPvtt8vPz8+qrwEAAMo5bt8DAAAoZfr3768zZ84oNjZWGRkZCgkJ0aZNmxQQECBJysjIUFpammP/hx9+WOfPn9eCBQs0YcIEVa9eXZ07d9bcuXOt+goAAACUUgAAAKVRVFSUoqKiCnxv+fLl+cYef/xxPf7448WcCgAAoOi4fQ8AAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYLobKqV27Nihhx56SG3btlV6erok6bXXXtPOnTtdGg4AAAAAAABlk+FSat26derevbsqVaqkAwcOKCcnR5J0/vx5zZ492+UBAQAAAAAAUPYYLqVmzpypxYsX65///KcqVqzoGA8PD9f+/ftdGg4AAAAAAABlk+FS6siRI+rQoUO+cW9vb/3888+uyAQAAAAAAIAyznApVb9+fX377bf5xnfu3Kng4GCXhAIAACirfvnlF6sjAAAAlAiGS6mRI0dq7Nix+uSTT2Sz2XTq1CmtXr1aEydOVFRUVHFkBAAAKNXy8vL07LPP6qabblLVqlV17NgxSdLTTz+tV155xeJ0AAAA1jBcSk2ePFl9+vRRp06ddOHCBXXo0EEjRozQyJEjNXr06OLICAAAUKrNnDlTy5cv17x58+Th4eEYb9GihV5++WULkwEAAFjHcCklSbNmzdLp06e1d+9e7dmzRz/++KOeffZZV2cDAAAoE1auXKmlS5dq0KBBcnNzc4y3bNlSX331lYXJAAAArONu9IBz584pNzdXNWvWVFhYmGP87Nmzcnd3l7e3t0sDAgAAlHbp6elq1KhRvvG8vDz9+uuvFiQCAACwnuErpQYMGKA33ngj3/ibb76pAQMGuCQUAABAWdK8eXPt2LEj3/jatWvVpk0bCxIBAABYz/CVUp988oni4+Pzjd99992aOnWqS0IBAACUJdOmTdPgwYOVnp6uvLw8rV+/XkeOHNHKlSv173//2+p4AAAAljB8pVROTo6uXr2ab/zXX3/V5cuXXRIKAACgLOnVq5eSkpK0adMm2Ww2PfPMMzp8+LA2bNigbt26WR0PAADAEoavlLrtttu0dOlSvfTSS07jixcvVmhoqMuCAQAAlCXdu3dX9+7drY4BAABQYhgupWbNmqWuXbvq4MGD6tKliyRpy5Yt+vTTT/XBBx+4PCAAAEBp9+mnnyovL0933HGH0/gnn3wiNzc3p4fHAAAAlBeGb99r166dPv74Y/n7++vNN9/Uhg0b1KhRI3322Wdq3759cWQEAAAo1UaNGqWTJ0/mG09PT9eoUaMsSAQAAGA9w1dKSVLr1q21evVqV2cBAAAokw4dOqRbb70133ibNm106NAhCxIBAABY74ZKqby8PH377bfKyspSXl6e03sdOnRwSTAAAICywtPTUz/88IOCg4OdxjMyMuTufkPTMQAAgFLP8Cxoz549GjhwoL777jvZ7Xan92w2m3Jzc10WDgAAoCzo1q2bYmJi9K9//Us+Pj6SpJ9//llPPvkkT98DAADlluFSKjIyUmFhYdq4caPq168vm81WHLkAAADKjBdeeEEdOnRQQECA2rRpI0lKTU2Vr6+vXnvtNYvTAQAAWMNwKfXNN9/orbfeUqNGjYojDwAAQJlz00036bPPPtPq1at18OBBVapUSY888ogefPBBVaxY0ep4AAAAljBcSt1xxx369ttvKaUAAAAMqFKliv7+979bHQMAAKDEMFxKPf7445owYYIyMzPVokWLfH/da9mypcvCAQAAlBVff/21tm7dWuCDYp555hmLUgEAAFjHcCnVt29fSdKwYcMcYzabTXa7nYXOAQAACvDPf/5Tjz32mGrXrq169eo5rclps9kopQAAQLlkuJQ6fvy4SwMkJibqueeeU0ZGhpo3b66EhAS1b9/+D4/btWuXOnbsqJCQEKWmpro0EwAAgCvNnDlTs2bN0hNPPGF1FAAAgBLDcCkVEBDgsg9PSkrSuHHjlJiYqHbt2mnJkiXq0aOHDh06pIYNGxZ63Llz5zRkyBB16dJFP/zwg8vyAAAAFIeffvpJDzzwgNUxAAAAShTDpdR1hw4dUlpamq5cueI0fu+99xb5HPHx8Ro+fLhGjBghSUpISNDmzZu1aNEixcXFFXrcyJEjNXDgQLm5uemdd965ofwAAABmeeCBB/TBBx8oMjLS6igAAAAlhuFS6tixY7rvvvv0+eefO9aSkuRYG6Goa0pduXJFKSkpmjJlitN4RESEdu/eXehxr776qo4ePapVq1Zp5syZf/g5OTk5ysnJcbzOzs4uUj4AAABXadSokZ5++mnt2bOnwAfFjBkzxqJkAAAA1jFcSo0dO1ZBQUH6z3/+o+DgYO3du1dnzpzRhAkT9Pzzzxf5PKdPn1Zubq58fX2dxn19fZWZmVngMd98842mTJmiHTt2yN29aNHj4uI0Y8aMIucCAABwtaVLl6pq1aratm2btm3b5vSezWajlAIAAOWS4VLq448/1ocffqg6deqoQoUKqlChgu666y7FxcVpzJgxOnDggKHz/e/TZyQ5nuL3W7m5uRo4cKBmzJihJk2aFPn8MTExio6OdrzOzs6Wv7+/oYwAAAB/hqsfFAMAAFAWGC6lcnNzVbVqVUlS7dq1derUKd18880KCAjQkSNHinye2rVry83NLd9VUVlZWfmunpKk8+fPa9++fTpw4IBGjx4tScrLy5Pdbpe7u7s++OADde7cOd9xnp6e8vT0NPIVAQAAAAAAUMwMl1IhISH67LPPFBwcrDvuuEPz5s2Th4eHli5dquDg4CKfx8PDQ6GhoUpOTtZ9993nGE9OTlbv3r3z7e/t7a3PP//caSwxMVEffvih3nrrLQUFBRn9KgAAAKb5/vvv9e677xb4oJj4+HiLUgEAAFjHcCn11FNP6eLFi5KkmTNn6m9/+5vat2+vWrVqKSkpydC5oqOjNXjwYIWFhalt27ZaunSp0tLSHE+miYmJUXp6ulauXKkKFSooJCTE6fi6devKy8sr3zgAAEBJsmXLFt17770KCgrSkSNHFBISohMnTshut+vWW2+1Oh4AAIAlDJdS3bt3d/wcHBysQ4cO6ezZs6pRo0aBa0H9nv79++vMmTOKjY1VRkaGQkJCtGnTJgUEBEiSMjIylJaWZjQiAABAiRITE6MJEyYoNjZW1apV07p161S3bl0NGjRIf/3rX62OBwAAYIkKrjhJzZo1DRdS10VFRenEiRPKyclRSkqKOnTo4Hhv+fLl2rp1a6HHTp8+XampqTf0uQAAAGY5fPiwhg4dKklyd3fX5cuXVbVqVcXGxmru3LkWpwMAALBGka6Uuv/++7V8+XJ5e3vr/vvv/919169f75JgAAAAZUWVKlWUk5MjSfLz89PRo0fVvHlzSdLp06etjAYAAGCZIpVSPj4+jiuhfHx8ijUQAABAWXPnnXdq165datasmXr27KkJEybo888/1/r163XnnXdaHQ8AAMASRSqlXn31VUmS3W7X9OnTVadOHVWuXLlYgwEAAJQV8fHxunDhgqRryw9cuHBBSUlJatSokV588UWL0wEAAFjD0ELndrtdjRs31pdffqnGjRsXVyYAAIAyJTg42PFz5cqVlZiYaGEaAACAksHQQucVKlRQ48aNdebMmeLKAwAAAAAAgHLA8NP35s2bp0mTJumLL74ojjwAAABlQs2aNR2LmNeoUUM1a9YsdAMAACiPDN2+J0kPPfSQLl26pFatWsnDw0OVKlVyev/s2bMuCwcAAFBavfjii6pWrZokKSEhwdowAAAAJZDhUopJFQAAwB8bOnSoJOnq1auSpO7du6tevXpWRgIAAChRDJdS1ydYAAAA+GPu7u567LHHdPjwYaujAAAAlCiGS6n/dfnyZf36669OY97e3n8qEAAAQFlzxx136MCBAwoICLA6CgAAQIlhuJS6ePGinnjiCb355psFPoUvNzfXJcEAAADKiqioKE2YMEHff/+9QkNDVaVKFaf3W7ZsaVEyAAAA6xgupSZPnqyPPvpIiYmJGjJkiBYuXKj09HQtWbJEc+bMKY6MAAAApVr//v0lSWPGjHGM2Ww22e122Ww2/qgHAADKJcOl1IYNG7Ry5UrdfffdGjZsmNq3b69GjRopICBAq1ev1qBBg4ojJwAAQKl1/PhxqyMAAACUOIZLqbNnzyooKEjStfWjzp49K0m666679Nhjj7k2HQAAQBnAWlIAAAD5GS6lgoODdeLECQUEBKhZs2Z68803dfvtt2vDhg2qXr16MUQEAAAoGw4dOqS0tDRduXLFafzee++1KBEAAIB1DJdSjzzyiA4ePKiOHTsqJiZGPXv21EsvvaSrV68qPj6+ODICAACUaseOHdN9992nzz//3LGWlHRtXSmJB8UAAIDyyXApNX78eMfPnTp10ldffaV9+/bpL3/5i1q1auXScAAAAGXB2LFjFRQUpP/85z8KDg7W3r17debMGU2YMEHPP/+81fEAAAAsYbiUOnHihAIDAx2vGzZsqIYNG7oyEwAAQJny8ccf68MPP1SdOnVUoUIFVahQQXfddZfi4uI0ZswYHThwwOqIAAAApqtg9IDg4GDdddddWrJkiWORcwAAABQuNzdXVatWlSTVrl1bp06dknRtAfQjR45YGQ0AAMAyhkupffv2qW3btpo5c6b8/PzUu3dvrV27Vjk5OcWRDwAAoNQLCQnRZ599Jkm64447NG/ePO3atUuxsbEKDg62OB0AAIA1DJdSt956q5577jmlpaXpvffeU926dTVy5EjVrVtXw4YNK46MAAAApdpTTz2lvLw8SdLMmTP13XffqX379tq0aZPmz59vcToAAABrGC6lrrPZbOrUqZP++c9/OhbtXLFihSuzAQAAlAndu3fX/fffL+naUgiHDh3S6dOnlZWVpc6dO1ucDgAAwBo3XEqdPHlS8+bNU+vWrXXbbbepSpUqWrBggSuzAQAAlAkrVqzQxYsXncZq1qwpm81mUSIAAADrGS6lli5dqo4dOyooKEgrVqxQv379dPToUe3cuVOPPfZYcWQEAAAo1SZOnKi6detqwIAB+ve//62rV69aHQkAAMByhkupZ599Vrfffrv27dunL7/8Uk8++aQCAwOLIRoAAEDZkJGRoaSkJLm5uWnAgAGqX7++oqKitHv3bqujAQAAWMbd6AFpaWlcag4AAGCAu7u7/va3v+lvf/ubLl26pLfffluvv/66OnXqpAYNGujo0aNWRwQAADCd4VKKQgoAAODGVa5cWd27d9dPP/2k7777TocPH7Y6EgAAgCVueKFzAAAAFN2lS5e0evVq3XPPPfLz89OLL76oPn366IsvvrA6GgAAgCUMXykFAAAAYx588EFt2LBBlStX1gMPPKCtW7cqPDzc6lgAAACWopQCAAAoZjabTUlJSerevbvc3Zl+AQAASJRSAAAAxe7111+3OgIAAECJU6RSqk2bNkVe4Hz//v1/KhAAAAAAAADKviKVUn369HH8/MsvvygxMVHNmjVT27ZtJUl79uzRl19+qaioqGIJCQAAAAAAgLKlSKXUtGnTHD+PGDFCY8aM0bPPPptvn5MnT7o2HQAAAAAAAMqkCkYPWLt2rYYMGZJv/KGHHtK6detcEgoAAAAAAABlm+GFzitVqqSdO3eqcePGTuM7d+6Ul5eXy4IBAACUZtnZ2UXe19vbuxiTAAAAlEyGr5QaN26cHnvsMY0ePVqrVq3SqlWrNHr0aI0aNUrjx48vjowAAAClTvXq1VWjRo0ibTciMTFRQUFB8vLyUmhoqHbs2PG7++fk5Gjq1KkKCAiQp6en/vKXv2jZsmU39NkAAACuYPhKqSlTpig4OFj/+Mc/HI83btq0qZYvX65+/fq5PCAAAEBp9NFHHzl+PnHihKZMmaKHH37Y8aCYjz/+WCtWrFBcXJzhcyclJWncuHFKTExUu3bttGTJEvXo0UOHDh1Sw4YNCzymX79++uGHH/TKK6+oUaNGysrK0tWrV2/sywEAALiA4VJKujapoYACAAAoXMeOHR0/x8bGKj4+Xg8++KBj7N5771WLFi20dOlSDR061NC54+PjNXz4cI0YMUKSlJCQoM2bN2vRokUFllzvv/++tm3bpmPHjqlmzZqSpMDAwBv4VgAAAK5j+PY9Sfr555/18ssv68knn9TZs2clSfv371d6erpLwwEAAJQFH3/8scLCwvKNh4WFae/evYbOdeXKFaWkpCgiIsJpPCIiQrt37y7wmHfffVdhYWGaN2+ebrrpJjVp0kQTJ07U5cuXC/2cnJwcZWdnO20AAACuZLiU+uyzz9SkSRPNnTtXzz33nH7++WdJ0ttvv62YmBhX5wMAACj1/P39tXjx4nzjS5Yskb+/v6FznT59Wrm5ufL19XUa9/X1VWZmZoHHHDt2TDt37tQXX3yht99+WwkJCXrrrbc0atSoQj8nLi5OPj4+js1oTgAAgD9i+Pa96OhoPfzww5o3b56qVavmGO/Ro4cGDhzo0nAAAABlwYsvvqi+fftq8+bNuvPOOyVJe/bs0dGjR7Vu3bobOqfNZnN6bbfb841dl5eXJ5vNptWrV8vHx0fStVsA/+///k8LFy5UpUqV8h0TExOj6Ohox+vs7GyKKQAA4FKGr5T69NNPNXLkyHzjN910U6F/nQMAACjP7rnnHn399de69957dfbsWZ05c0a9e/fW119/rXvuucfQuWrXri03N7d8866srKx8V09dV79+fd10002OQkq69qAau92u77//vsBjPD095e3t7bQBAAC4kuErpby8vApcU+DIkSOqU6eOS0IBAACUNf7+/po9e/afPo+Hh4dCQ0OVnJys++67zzGenJys3r17F3hMu3bttHbtWl24cEFVq1aVJH399deqUKGCGjRo8KczAQAA3AjDV0r17t1bsbGx+vXXXyVdu3Q8LS1NU6ZMUd++fV0eEAAAoCzYsWOHHnroIYWHhzseDvPaa69p586dhs8VHR2tl19+WcuWLdPhw4c1fvx4paWlKTIyUtK1W++GDBni2H/gwIGqVauWHnnkER06dEjbt2/XpEmTNGzYsAJv3QMAADCD4VLq+eef148//qi6devq8uXL6tixoxo1aqRq1app1qxZxZERAACgVFu3bp26d++uSpUqaf/+/crJyZEknT9//oaunurfv78SEhIUGxur1q1ba/v27dq0aZMCAgIkSRkZGUpLS3PsX7VqVSUnJ+vnn39WWFiYBg0apF69emn+/Pmu+YIAAAA3wPDte97e3tq5c6c+/PBD7d+/X3l5ebr11lvVtWvX4sgHAABQ6s2cOVOLFy/WkCFD9MYbbzjGw8PDFRsbe0PnjIqKUlRUVIHvLV++PN/YLbfcouTk5Bv6LAAAgOJguJS6rnPnzurcubMrswAAAJRJR44cUYcOHfKNe3t76+effzY/EAAAQAlwQ6XUli1btGXLFmVlZSkvL8/pvWXLlrkkGAAAQFlRv359ffvttwoMDHQa37lzp4KDg60JBQAAYDHDa0rNmDFDERER2rJli06fPq2ffvrJaQMAAICzkSNHauzYsfrkk09ks9l06tQprV69WhMnTiz0FjwAAICyzvCVUosXL9by5cs1ePDg4sgDAABQ5kyePFnnzp1Tp06d9Msvv6hDhw7y9PTUxIkTNXr0aKvjAQAAWMJwKXXlyhWFh4cXRxYAAIAya9asWZo6daoOHTqkvLw8NWvWTFWrVrU6FgAAgGUMl1IjRozQ66+/rqeffro48gAAAJRZlStXVlhYmNUxSqzAKRutjlCoE3N6Wh0BAIAyx3Ap9csvv2jp0qX6z3/+o5YtW6pixYpO78fHx7ssHAAAQFlw8eJFzZkzp9AHxRw7dsyiZAAAANYxXEp99tlnat26tSTpiy++cHrPZrO5JBQAAEBZMmLECG3btk2DBw9W/fr1mTMBAADoBkqpjz76qDhyAAAAlFnvvfeeNm7cqHbt2lkdBQAAoMSoYHUAAACAsq5GjRqqWbOm1TEAAABKlCJdKXX//fdr+fLl8vb21v333/+7+65fv94lwQAAAMqKZ599Vs8884xWrFihypUrWx0HAACgRChSKeXj4+NY+8DHx6dYAwEAAJQ1L7zwgo4ePSpfX18FBgbme1DM/v37LUoGAABgnSKVUq+++mqBPwMAAOCP9enTx+oIAAAAJY7hhc4BAABgzLRp06yOAAAAUOLcUCn11ltv6c0331RaWpquXLni9B6XnwMAAAAAAOCPGH763vz58/XII4+obt26OnDggG6//XbVqlVLx44dU48ePYojIwAAQKlTs2ZNnT59WtJ/n75X2AYAAFAeGb5SKjExUUuXLtWDDz6oFStWaPLkyQoODtYzzzyjs2fPFkdGAACAUufFF19UtWrVJEkJCQnWhgEAACiBDJdSaWlpCg8PlyRVqlRJ58+flyQNHjxYd955pxYsWODahAAAAKXQ0KFDC/wZAAAA1xi+fa9evXo6c+aMJCkgIEB79uyRJB0/flx2u9216QAAAMqYy5cvKzs722kDAAAojwyXUp07d9aGDRskScOHD9f48ePVrVs39e/fX/fdd5/LAwIAAJR2Fy9e1OjRo1W3bl1VrVpVNWrUcNoAAADKI8O37y1dulR5eXmSpMjISNWsWVM7d+5Ur169FBkZ6fKAAAAApd3kyZP10UcfKTExUUOGDNHChQuVnp6uJUuWaM6cOVbHAwAAsIThUqpChQqqUOG/F1j169dP/fr1c2koAACAsmTDhg1auXKl7r77bg0bNkzt27dXo0aNFBAQoNWrV2vQoEFWRwQAADBdkUqpzz77rMgnbNmy5Q2HAQAAKIvOnj2roKAgSZK3t7fjicV33XWXHnvsMSujAQAAWKZIpVTr1q1ls9n+cCFzm82m3NxclwQDAAAoK4KDg3XixAkFBASoWbNmevPNN3X77bdrw4YNql69utXxAAAALFGkUur48ePFnQMAAKDMeuSRR3Tw4EF17NhRMTEx6tmzp1566SVdvXpV8fHxVscDAACwRJFKqYCAgOLOAQAAUGaNHz/e8XOnTp301Vdfad++ffrLX/6iVq1aWZgMAADAOhX+eJf8jhw5otGjR6tLly7q2rWrRo8erSNHjrg6GwAAQJmwcuVK5eTkOF43bNhQ999/v5o2baqVK1damAwAAMA6hkupt956SyEhIUpJSVGrVq3UsmVL7d+/XyEhIVq7dm1xZAQAACjVHnnkEZ07dy7f+Pnz5/XII49YkAgAAMB6hkupyZMnKyYmRh9//LHi4+MVHx+v3bt368knn9QTTzxhOEBiYqKCgoLk5eWl0NBQ7dixo9B9d+7cqXbt2qlWrVqqVKmSbrnlFr344ouGPxMAAMBMdrtdNpst3/j3338vHx8fCxIBAABYr0hrSv2vzMxMDRkyJN/4Qw89pOeee87QuZKSkjRu3DglJiaqXbt2WrJkiXr06KFDhw6pYcOG+favUqWKRo8erZYtW6pKlSrauXOnRo4cqSpVqujvf/+70a8CAABQrNq0aSObzSabzaYuXbrI3f2/U6/c3FwdP35cf/3rXy1MCAAAYB3DpdTdd9+tHTt2qFGjRk7jO3fuVPv27Q2dKz4+XsOHD9eIESMkSQkJCdq8ebMWLVqkuLi4fPu3adNGbdq0cbwODAzU+vXrtWPHDkopAABQ4vTp00eSlJqaqu7du6tq1aqO9zw8PBQYGKi+fftalA4AAMBahkupe++9V0888YRSUlJ05513SpL27NmjtWvXasaMGXr33Xed9i3MlStXlJKSoilTpjiNR0REaPfu3UXKcuDAAe3evVszZ84sdJ+cnBynhUWzs7OLdG4AAIA/a9q0aZKu/SGtf//+8vLysjgRAABAyWG4lIqKipJ0bS2oxMTEAt+TJJvNptzc3ELPc/r0aeXm5srX19dp3NfXV5mZmb+boUGDBvrxxx919epVTZ8+3XGlVUHi4uI0Y8aM3z0fAABAcRo6dKh+/vlnrVq1SkePHtWkSZNUs2ZN7d+/X76+vrrpppusjggAAGA6w6VUXl6eSwP8dtHPwhYC/V87duzQhQsXtGfPHk2ZMkWNGjXSgw8+WOC+MTExio6OdrzOzs6Wv7//nw8OAABQRJ999pm6du0qHx8fnThxQo8++qhq1qypt99+W999951WrlxpdUQAAADTGS6lfs+lS5dUuXLlIu1bu3Ztubm55bsqKisrK9/VU78VFBQkSWrRooV++OEHTZ8+vdBSytPTU56enkXKBAAAUBzGjx+vhx9+WPPmzVO1atUc4z169NDAgQMtTAYAAGCdCkYPuPvuu/X999/nG//kk0/UunXrIp/Hw8NDoaGhSk5OdhpPTk5WeHh4kc9jt9ud1owCAAAoafbt26eRI0fmG7/pppv+cNkCAACAsspwKeXt7a2WLVvqjTfekHTtdr7p06erQ4cOv7uweUGio6P18ssva9myZTp8+LDGjx+vtLQ0RUZGSrp2692QIUMc+y9cuFAbNmzQN998o2+++Uavvvqqnn/+eT300ENGvwYAAIBpvLy8CnzYypEjR1SnTh0LEgEAAFjP8O177777rhYvXqwRI0bo3Xff1YkTJ5SWlqaNGzeqa9euhs7Vv39/nTlzRrGxscrIyFBISIg2bdqkgIAASVJGRobS0tIc++fl5SkmJkbHjx+Xu7u7/vKXv2jOnDkF/uURAACgpOjdu7diY2P15ptvSrq2pmZaWpqmTJmivn37WpwOAADAGje0plRkZKS+++47zZ07V+7u7tq6dauhW+7+V1RUlNNT+/7X8uXLnV4//vjjevzxx2/ocwAAAKzy/PPP65577lHdunV1+fJldezYUZmZmWrbtq1mzZpldTwAAABLGC6lfvrpJ40YMUJbtmzRkiVLtG3bNkVERGjevHmFlksAAADlmbe3t3bu3KkPP/xQ+/fvV15enm699VbDV5kDAACUJYZLqZCQEAUFBenAgQMKCgrSo48+qqSkJEVFRWnjxo3auHFjceQEAAAola5evSovLy+lpqaqc+fO6ty5s9WRAAAASgTDC51HRkZq+/btCgoKcoz1799fBw8e1JUrV1waDgAAoLRzd3dXQECAcnNzrY4CAABQohgupZ5++mlVqHDtsF9++cUx3qBBAyUnJ7suGQAAQBnx1FNPKSYmRmfPnrU6CgAAQIlh+Pa9vLw8zZo1S4sXL9YPP/ygr7/+WsHBwXr66acVGBio4cOHF0dOAACAUmv+/Pn69ttv5efnp4CAAFWpUsXp/f3791uUDAAAwDqGS6mZM2dqxYoVmjdvnh599FHHeIsWLfTiiy9SSgEAAPxGnz59rI4AAABQ4hgupVauXKmlS5eqS5cuioyMdIy3bNlSX331lUvDAQAAlAXTpk2zOgIAAECJY3hNqfT0dDVq1CjfeF5enn799VeXhAIAAAAAAEDZZriUat68uXbs2JFvfO3atWrTpo1LQgEAAAAAAKBsM3z73rRp0zR48GClp6crLy9P69ev15EjR7Ry5Ur9+9//Lo6MAAAAAAAAKGMMXynVq1cvJSUladOmTbLZbHrmmWd0+PBhbdiwQd26dSuOjAAAAKVOdna21REAAABKNMNXSklS9+7d1b17d1dnAQAAKDNq1KihjIwM1a1bV507d9b69etVvXp1q2MBAACUGIavlAIAAMAfq1q1qs6cOSNJ2rp1Kw+EAQAA+I0bulIKAAAAv69r167q1KmTmjZtKkm677775OHhUeC+H374oZnRAAAASgRKKQAAgGKwatUqrVixQkePHtW2bdvUvHlzVa5c2epYAAAAJUaRSqns7Gx5e3sXdxYAAIAyo1KlSoqMjJQk7du3T3PnzmVNKQAAgP9RpDWlatSooaysLElS586d9fPPPxdnJgAAgDLlo48+chRSdrtddrvd2kAAAAAlQJFKKRbqBAAA+HNWrlypFi1aqFKlSqpUqZJatmyp1157zepYAAAAlinS7Xss1AkAAHDj4uPj9fTTT2v06NFq166d7Ha7du3apcjISJ0+fVrjx4+3OiIAAIDpilRKsVAnAADAjXvppZe0aNEiDRkyxDHWu3dvNW/eXNOnT6eUAgAA5VKRSikW6gQAALhxGRkZCg8PzzceHh6ujIwMCxIBAABYr0hrSv0vFuoEAAAwplGjRnrzzTfzjSclJalx48YWJAIAALBeka6U+q2VK1fqueee0zfffCNJatKkiSZNmqTBgwe7NBwAAEBZMGPGDPXv31/bt29Xu3btZLPZtHPnTm3ZsqXAsgoAAKA8MFxKsVAnAACAMX379tUnn3yiF198Ue+8847sdruaNWumvXv3qk2bNlbHAwAAsIThUoqFOsuHwCkbrY5QqBNzelodAQAAw0JDQ7Vq1SqrYwAAAJQYhteUYqFOAAAAAAAA/FmGSykW6gQAAAAAAMCfZfj2PRbqBAAAAAAAwJ9l+Eqp6wt11q5dW++8847Wr1+v2rVra+/evbrvvvuKIyMAAAAAAADKGMNXSkks1AkAAAAAAIA/54ZKKQAAABTdxYsXNWfOHG3ZskVZWVnKy8tzev/YsWMWJQMAALAOpRQAAEAxGzFihLZt26bBgwerfv36stlsVkcCAACwHKUUAABAMXvvvfe0ceNGtWvXzuooAAAAJYbhhc4BAABgTI0aNVSzZk2rYwAAAJQolFIAAADF7Nlnn9UzzzyjS5cuWR0FAACgxDB8+x4LdQIAABjzwgsv6OjRo/L19VVgYKAqVqzo9P7+/fstSgYAAGAdw6UUC3UCAAAY06dPH6sjAAAAlDiGSykW6gQAADBm2rRpVkcAAAAocQyXUizUCQAAcGNSUlJ0+PBh2Ww2NWvWTG3atLE6EgAAgGUMl1LXF+pcsWKFKleuXByZAAAAypSsrCwNGDBAW7duVfXq1WW323Xu3Dl16tRJb7zxhurUqWN1RAAAANMZLqVYqBMAAMCYxx9/XNnZ2fryyy/VtGlTSdKhQ4c0dOhQjRkzRmvWrLE4IQAAgPkMl1Is1AkAAGDM+++/r//85z+OQkqSmjVrpoULFyoiIsLCZAAAANYxXEqxUCcAAIAxeXl5+a4ul6SKFSsqLy/PgkQAAADWM1xKXcdCnQAAAEXTuXNnjR07VmvWrJGfn58kKT09XePHj1eXLl0sTgcAAGANw6UUC3UCAAAYs2DBAvXu3VuBgYHy9/eXzWZTWlqaWrRooVWrVlkdDwAAwBKGSykW6gQAADDG399f+/fvV3Jysr766ivZ7XY1a9ZMXbt2tToaAACAZQyXUizUCQAAcGO6deumbt26WR0DAACgRDBcSrFQJwAAwB+bP3++/v73v8vLy0vz58//3X3HjBljUioAAICSw3ApxUKdAAAAf+zFF1/UoEGD5OXlpRdffLHQ/Ww2G6UUAAAolwyXUizUCQAA8MeOHz9e4M8AAAC4poLRA64v1Llx40aNGzdOY8aM0aZNm5SSkqIGDRoUR0YAAIBSLTY2VpcuXco3fvnyZcXGxt7QORMTExUUFCQvLy+FhoZqx44dRTpu165dcnd3V+vWrW/ocwEAAFzFcCl1Xbdu3fT4449rzJgxPDkGAADgd8yYMUMXLlzIN37p0iXNmDHD8PmSkpI0btw4TZ06VQcOHFD79u3Vo0cPpaWl/e5x586d05AhQ1hyAQAAlAhFun2PhToBAABunN1ul81myzd+8OBB1axZ0/D54uPjNXz4cI0YMUKSlJCQoM2bN2vRokWKi4sr9LiRI0dq4MCBcnNz0zvvvGP4cwEAAFypSKUUC3UCAAAYV6NGDdlsNtlsNjVp0sSpmMrNzdWFCxcUGRlp6JxXrlxRSkqKpkyZ4jQeERGh3bt3F3rcq6++qqNHj2rVqlWaOXPmH35OTk6OcnJyHK+zs7MN5QQAAPgjRSqlWKgTAADAuISEBNntdg0bNkwzZsyQj4+P4z0PDw8FBgaqbdu2hs55+vRp5ebmytfX12nc19dXmZmZBR7zzTffaMqUKdqxY4fc3Yv2nJu4uLgburUQAACgqAw/fS82NlYTJ05U5cqVncYvX76s5557Ts8884zLwgEAAJRmQ4cO1dWrVyVJXbt2delDYX57O2Bhtwjm5uZq4MCBmjFjhpo0aVLk88fExCg6OtrxOjs7W/7+/jceGAAA4DcML3Tu6oU6AQAAyjJ3d3dFRUUpNzfXJeerXbu23Nzc8l0VlZWVle/qKUk6f/689u3bp9GjR8vd3V3u7u6KjY3VwYMH5e7urg8//LDAz/H09JS3t7fTBgAA4EqGSylXL9QJAABQ1t1xxx06cOCAS87l4eGh0NBQJScnO40nJycrPDw83/7e3t76/PPPlZqa6tgiIyN18803KzU1VXfccYdLcgEAABhV5Nv3imOhTgAAgPIgKipKEyZM0Pfff6/Q0FBVqVLF6f2WLVsaOl90dLQGDx6ssLAwtW3bVkuXLlVaWppjLhYTE6P09HStXLlSFSpUUEhIiNPxdevWlZeXV75xAAAAMxW5lCqOhToBAADKg/79+0uS01OKbTab4wp0o7f29e/fX2fOnFFsbKwyMjIUEhKiTZs2KSAgQJKUkZGhtLQ0130BAACAYlDkUqo4F+oEAAAoy4rj6cVRUVGKiooq8L3ly5f/7rHTp0/X9OnTXZ4JAADACENP37u+UOfhw4eLKw8AAECZc/0KJgAAAPyXoVJK+u9CnUyuAAAAiu7o0aNKSEjQ4cOHZbPZ1LRpU40dO1Z/+ctfrI4GAABgCcOllKsX6gQAACjrNm/erHvvvVetW7dWu3btZLfbtXv3bjVv3lwbNmxQt27drI4IAABgOsOllKsX6gQAACjrpkyZovHjx2vOnDn5xp944glKKQAAUC4ZLqWKY6FOAACAsuzw4cN68803840PGzZMCQkJ5gcCAAAoAQyXUqwlBQAAYEydOnWUmpqqxo0bO42npqaqbt26FqUCAACwluFSSmKhTgAAACMeffRR/f3vf9exY8cUHh4um82mnTt3au7cuZowYYLV8QAAACxhuJRioU4AAABjnn76aVWrVk0vvPCCYmJiJEl+fn6aPn260zqdAAAA5YnhUoqFOgEAAIyx2WwaP368xo8fr/Pnz0uSqlWrZnEqAAAAa1UwesDhw4c1fPjwfOPDhg3ToUOHXBIKAACgLMrKylJqaqoOHjyoH3/80eo4AAAAljJcSl1fqPO3WKgTAACgYNnZ2Ro8eLD8/PzUsWNHdejQQX5+fnrooYd07tw5q+MBAABYwvDteyzUCQAAYMyIESOUmpqqjRs3qm3btrLZbNq9e7fGjh2rRx99VG+++abVEQEAAExnuJRioU4AAABjNm7cqM2bN+uuu+5yjHXv3l3//Oc/9de//tXCZAAAANYxXEqxUCcAAIAxtWrVko+PT75xHx8f1ahRw4JEAAAA1jO8ptR1LNQJAABQNE899ZSio6OVkZHhGMvMzNSkSZP09NNPW5gMAADAOoZLKVcv1JmYmKigoCB5eXkpNDRUO3bsKHTf9evXq1u3bqpTp468vb3Vtm1bbd682fBnAgAAmGnRokXas2ePAgIC1KhRIzVq1EgNGzbU7t27tWTJEt16662ODQAAoLwwfPueKxfqTEpK0rhx45SYmKh27dppyZIl6tGjhw4dOqSGDRvm23/79u3q1q2bZs+ererVq+vVV19Vr1699Mknn6hNmzZGvwoAAIAp+vTpY3UEAACAEsdwKeXKhTrj4+M1fPhwjRgxQpKUkJCgzZs3a9GiRYqLi8u3f0JCgtPr2bNn61//+pc2bNhAKQUAAEqsadOmWR0BAACgxDFcSrlqoc4rV64oJSVFU6ZMcRqPiIjQ7t27i3SOvLw8nT9/XjVr1ix0n5ycHOXk5DheZ2dnFzkjAACAK6WkpOjw4cOy2Wxq1qwZf1QDAADlmuE1pVy1UOfp06eVm5srX19fp3FfX19lZmYW6RwvvPCCLl68qH79+hW6T1xcnHx8fBybv79/kTMCAAC4QlZWljp37qzbbrtNY8aM0ejRoxUaGqouXbrwwBgAAFBuGS6lXL1Qp81mc3ptt9vzjRVkzZo1mj59upKSklS3bt1C94uJidG5c+cc28mTJ4uUCwAAwFUef/xxZWdn68svv9TZs2f1008/6YsvvlB2drbGjBljdTwAAABLGL59z1ULddauXVtubm75rorKysrKd/XUbyUlJWn48OFau3atunbt+rv7enp6ytPT80/nBQAAuFHvv/++/vOf/6hp06aOsWbNmmnhwoWKiIiwMBkAAIB1DJdSrlqo08PDQ6GhoUpOTtZ9993nGE9OTlbv3r0LPW7NmjUaNmyY1qxZo549e7okCwAAQHHKy8tTxYoV841XrFhReXl5FiQCAACwnuFS6jpXLNQZHR2twYMHKywsTG3bttXSpUuVlpamyMhISdduvUtPT9fKlSslXSukhgwZon/84x+68847HVdZVapUqcDF1wEAAEqCzp07a+zYsVqzZo38/PwkSenp6Ro/fry6dOlicToAAABrGC6lsrKyNGDAAG3dulXVq1eX3W7XuXPn1KlTJ73xxhuqU6dOkc/Vv39/nTlzRrGxscrIyFBISIg2bdqkgIAASVJGRobS0tIc+y9ZskRXr17VqFGjNGrUKMf40KFDtXz5cqNfBQAAwBQLFixQ7969FRgYKH9/f9lsNqWlpalFixZatWqV1fEAAAAsYbiU+t+FOq+vi3Do0CENHTpUY8aM0Zo1awydLyoqSlFRUQW+99uiaevWrUbjAgAAWM7f31/79+9XcnKyvvrqK9ntdjVr1uwP18YEAAAoywyXUizUCQAAUHRXr16Vl5eXUlNT1a1bN3Xr1s3qSAAAACVCBaMHsFAnAABA0bm7uysgIEC5ublWRwEAAChRDJdS1xfqPHXqlGOMhToBAAAK99RTTykmJkZnz561OgoAAECJYfj2PRbqBAAAMGb+/Pn69ttv5efnp4CAAFWpUsXp/f3791uUDAAAwDqGSykW6gQAADCmd+/estlsVscAAAAoUQyVUizUCQAAYNz06dOtjgAAAFDiGFpTioU6AQAAiu7SpUsaNWqUbrrpJtWtW1cDBw7U6dOnrY4FAABQIhhe6JyFOgEAAIpm2rRpWr58uXr27KkBAwYoOTlZjz32mNWxAAAASgTDa0qxUCcAAEDRrF+/Xq+88ooGDBggSXrooYfUrl075ebmys3NzeJ0AAAA1jJcSrFQJwAAQNGcPHlS7du3d7y+/fbb5e7urlOnTsnf39/CZAAAANYzXEqxUCcAAEDR5ObmysPDw2nM3d1dV69etSgRAABAyVHkUurSpUuaNGmS3nnnHf3666/q2rWr5s+fr9q1axdnPgAAgFLLbrfr4Ycflqenp2Psl19+UWRkpNMSCOvXr7ciHgAAgKWKXEpdX6hz0KBB8vLy0po1a/TYY49p7dq1xZkPAACg1Bo6dGi+sYceesiCJAAAACVPkUspFuoEAAAw5tVXX7U6AgAAQIlVoag7/t5CnQAAAAAAAIARRS6lWKgTAAAAAAAArlLk2/dYqBMAAAAAAACuUuRSioU6AQAAAAAA4CpFLqVYqBMAAAAAAACuUuQ1pQAAAAAAAABXoZQCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAKAUSkxMVFBQkLy8vBQaGqodO3YUuu/69evVrVs31alTR97e3mrbtq02b95sYloAAID8KKUAAABKmaSkJI0bN05Tp07VgQMH1L59e/Xo0UNpaWkF7r99+3Z169ZNmzZtUkpKijp16qRevXrpwIEDJicHAAD4L0opAACAUiY+Pl7Dhw/XiBEj1LRpUyUkJMjf31+LFi0qcP+EhARNnjxZt912mxo3bqzZs2ercePG2rBhg8nJAQAA/otSCgAAoBS5cuWKUlJSFBER4TQeERGh3bt3F+kceXl5On/+vGrWrFnoPjk5OcrOznbaAAAAXIlSCgAAoBQ5ffq0cnNz5evr6zTu6+urzMzMIp3jhRde0MWLF9WvX79C94mLi5OPj49j8/f3/1O5AQAAfotSCgAAoBSy2WxOr+12e76xgqxZs0bTp09XUlKS6tatW+h+MTExOnfunGM7efLkn84MAADwv9ytDgAAAICiq127ttzc3PJdFZWVlZXv6qnfSkpK0vDhw7V27Vp17dr1d/f19PSUp6fnn84LAABQGK6UAgAAKEU8PDwUGhqq5ORkp/Hk5GSFh4cXetyaNWv08MMP6/XXX1fPnj2LOyYAAMAf4kopAACAUiY6OlqDBw9WWFiY2rZtq6VLlyotLU2RkZGSrt16l56erpUrV0q6VkgNGTJE//jHP3TnnXc6rrKqVKmSfHx8LPseAACgfKOUAgAAKGX69++vM2fOKDY2VhkZGQoJCdGmTZsUEBAgScrIyFBaWppj/yVLlujq1asaNWqURo0a5RgfOnSoli9fbnZ8AAAASZRSAAAApVJUVJSioqIKfO+3RdPWrVuLPxAAAIBBrCkFAAAAAAAA01FKAQAAAAAAwHSWl1KJiYkKCgqSl5eXQkNDtWPHjkL3zcjI0MCBA3XzzTerQoUKGjdunHlBAQAAAAAA4DKWllJJSUkaN26cpk6dqgMHDqh9+/bq0aOH08Kc/ysnJ0d16tTR1KlT1apVK5PTAgAAAAAAwFUsLaXi4+M1fPhwjRgxQk2bNlVCQoL8/f21aNGiAvcPDAzUP/7xDw0ZMoTHFwMAAAAAAJRilpVSV65cUUpKiiIiIpzGIyIitHv3bpd9Tk5OjrKzs502AAAAAAAAWMuyUur06dPKzc2Vr6+v07ivr68yMzNd9jlxcXHy8fFxbP7+/i47NwAAAAAAAG6M5Qud22w2p9d2uz3f2J8RExOjc+fOObaTJ0+67NwAAAAAAAC4Me5WfXDt2rXl5uaW76qorKysfFdP/Rmenp7y9PR02fkAAAAAAADw51l2pZSHh4dCQ0OVnJzsNJ6cnKzw8HCLUgEAAAAAAMAMll0pJUnR0dEaPHiwwsLC1LZtWy1dulRpaWmKjIyUdO3Wu/T0dK1cudJxTGpqqiTpwoUL+vHHH5WamioPDw81a9bMiq8AAAAAAACAG2BpKdW/f3+dOXNGsbGxysjIUEhIiDZt2qSAgABJUkZGhtLS0pyOadOmjePnlJQUvf766woICNCJEyfMjA4AAAAAAIA/wdJSSpKioqIUFRVV4HvLly/PN2a324s5EQAAAAAAAIqb5U/fAwAAAAAAQPlDKQUAAAAAAADTUUoBAAAAAADAdJRSAAAAAAAAMB2lFAAAAAAAAExHKQUAAAAAAADTUUoBAAAAAADAdJRSAAAAAAAAMB2lFAAAAAAAAExHKQUAAAAAAADTUUoBAAAAAADAdJRSAAAAAAAAMB2lFAAAAAAAAExHKQUAAAAAAADTUUoBAAAAAADAdJRSAAAAAAAAMB2lFAAAAAAAAExHKQUAAAAAAADTUUoBAAAAAADAdJRSAAAAAAAAMB2lFAAAAAAAAExHKQUAAAAAAADTUUoBAAAAAADAdJRSAAAAAAAAMB2lFAAAAAAAAExHKQUAAAAAAADTUUoBAAAAAADAdJRSAAAAAAAAMJ271QGA4hI4ZaPVEQp1Yk5PqyMAAAAAAGAprpQCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJiOUgoAAAAAAACmo5QCAAAAAACA6SilAAAAAAAAYDpKKQAAAAAAAJjO3eoAAAoXOGWj1REKdWJOT6sjAAAAAABKMa6UAgAAAAAAgOkopQAAAAAAAGA6SikAAAAAAACYjjWlABQr1sUCAAAAABSEUgoAfgelGgAAAAAUD27fAwAAAAAAgOkopQAAAAAAAGA6SikAAAAAAACYjlIKAAAAAAAApqOUAgAAAAAAgOkopQAAAAAAAGA6d6sDAACKV+CUjVZHKNSJOT2tjgAAAADAIlwpBQAAAAAAANNRSgEAAAAAAMB0lFIAAAAAAAAwHaUUAAAAAAAATMdC5wCAEo/F2gEAAICyhyulAAAAAAAAYDqulAIAwARc7QUAAAA4s/xKqcTERAUFBcnLy0uhoaHasWPH7+6/bds2hYaGysvLS8HBwVq8eLFJSQEAAEoO5lAAAKC0s7SUSkpK0rhx4zR16lQdOHBA7du3V48ePZSWllbg/sePH9c999yj9u3b68CBA3ryySc1ZswYrVu3zuTkAAAA1mEOBQAAygJLb9+Lj4/X8OHDNWLECElSQkKCNm/erEWLFikuLi7f/osXL1bDhg2VkJAgSWratKn27dun559/Xn379jUzOgAA5Q63IJYczKEAAEBZYFkpdeXKFaWkpGjKlClO4xEREdq9e3eBx3z88ceKiIhwGuvevbteeeUV/frrr6pYsWK+Y3JycpSTk+N4fe7cOUlSdnb2n/0KhcrLuVRs5/6zivq9+Q7Fi+9QMhTlO5T2/BLfobjxHUqG4vz/9evnttvtxfYZRjCHskZ5+e+ktOeX+A7Fje9QMvDfs/XK03f4M+f+w/mT3SLp6el2SfZdu3Y5jc+aNcvepEmTAo9p3LixfdasWU5ju3btskuynzp1qsBjpk2bZpfExsbGxsbGxvantpMnT7pmEvQnMYdiY2NjY2NjKy3bH82fLH/6ns1mc3ptt9vzjf3R/gWNXxcTE6Po6GjH67y8PJ09e1a1atX63c+B62RnZ8vf318nT56Ut7e31XHKJX4HJQO/B+vxOygZStvvwW636/z58/Lz87M6ihPmUGVbafvvpKzi92A9fgclA7+HkqE0/R6KOn+yrJSqXbu23NzclJmZ6TSelZUlX1/fAo+pV69egfu7u7urVq1aBR7j6ekpT09Pp7Hq1avfeHDcMG9v7xL/H05Zx++gZOD3YD1+ByVDafo9+Pj4WB3BgTlU+VKa/jspy/g9WI/fQcnA76FkKC2/h6LMnyx7+p6Hh4dCQ0OVnJzsNJ6cnKzw8PACj2nbtm2+/T/44AOFhYUVuBYCAABAWcMcCgAAlBWWlVKSFB0drZdfflnLli3T4cOHNX78eKWlpSkyMlLStcvGhwwZ4tg/MjJS3333naKjo3X48GEtW7ZMr7zyiiZOnGjVVwAAADAdcygAAFAWWLqmVP/+/XXmzBnFxsYqIyNDISEh2rRpkwICAiRJGRkZSktLc+wfFBSkTZs2afz48Vq4cKH8/Pw0f/58HmVcwnl6emratGn5bgGAefgdlAz8HqzH76Bk4Pfw5zGHKvv476Rk4PdgPX4HJQO/h5KhLP4ebHZ7CXm+MQAAAAAAAMoNS2/fAwAAAAAAQPlEKQUAAAAAAADTUUoBAAAAAADAdJRSAAAAAAAAMB2lFIpFXFycbrvtNlWrVk1169ZVnz59dOTIEatjlWtxcXGy2WwaN26c1VHKnfT0dD300EOqVauWKleurNatWyslJcXqWOXK1atX9dRTTykoKEiVKlVScHCwYmNjlZeXZ3W0Mm379u3q1auX/Pz8ZLPZ9M477zi9b7fbNX36dPn5+alSpUq6++679eWXX1oTFighmEOVPMyhrMMcynrMocxX3uZPlFIoFtu2bdOoUaO0Z88eJScn6+rVq4qIiNDFixetjlYuffrpp1q6dKlatmxpdZRy56efflK7du1UsWJFvffeezp06JBeeOEFVa9e3epo5crcuXO1ePFiLViwQIcPH9a8efP03HPP6aWXXrI6Wpl28eJFtWrVSgsWLCjw/Xnz5ik+Pl4LFizQp59+qnr16qlbt246f/68yUmBkoM5VMnCHMo6zKFKBuZQ5itv8yeb3W63Wx0CZd+PP/6ounXratu2berQoYPVccqVCxcu6NZbb1ViYqJmzpyp1q1bKyEhwepY5caUKVO0a9cu7dixw+oo5drf/vY3+fr66pVXXnGM9e3bV5UrV9Zrr71mYbLyw2az6e2331afPn0kXfsrn5+fn8aNG6cnnnhCkpSTkyNfX1/NnTtXI0eOtDAtUHIwh7IOcyhrMYcqGZhDWas8zJ+4UgqmOHfunCSpZs2aFicpf0aNGqWePXuqa9euVkcpl959912FhYXpgQceUN26ddWmTRv985//tDpWuXPXXXdpy5Yt+vrrryVJBw8e1M6dO3XPPfdYnKz8On78uDIzMxUREeEY8/T0VMeOHbV7924LkwElC3Mo6zCHshZzqJKBOVTJUhbnT+5WB0DZZ7fbFR0drbvuukshISFWxylX3njjDe3fv1+ffvqp1VHKrWPHjmnRokWKjo7Wk08+qb1792rMmDHy9PTUkCFDrI5XbjzxxBM6d+6cbrnlFrm5uSk3N1ezZs3Sgw8+aHW0ciszM1OS5Ovr6zTu6+ur7777zopIQInDHMo6zKGsxxyqZGAOVbKUxfkTpRSK3ejRo/XZZ59p586dVkcpV06ePKmxY8fqgw8+kJeXl9Vxyq28vDyFhYVp9uzZkqQ2bdroyy+/1KJFi5hQmSgpKUmrVq3S66+/rubNmys1NVXjxo2Tn5+fhg4danW8cs1mszm9ttvt+caA8oo5lDWYQ5UMzKFKBuZQJVNZmj9RSqFYPf7443r33Xe1fft2NWjQwOo45UpKSoqysrIUGhrqGMvNzdX27du1YMEC5eTkyM3NzcKE5UP9+vXVrFkzp7GmTZtq3bp1FiUqnyZNmqQpU6ZowIABkqQWLVrou+++U1xcHBMqi9SrV0/Stb/41a9f3zGelZWV769/QHnEHMo6zKFKBuZQJQNzqJKlLM6fWFMKxcJut2v06NFav369PvzwQwUFBVkdqdzp0qWLPv/8c6Wmpjq2sLAwDRo0SKmpqUymTNKuXbt8j/L++uuvFRAQYFGi8unSpUuqUMH5//Lc3Nx4nLGFgoKCVK9ePSUnJzvGrly5om3btik8PNzCZIC1mENZjzlUycAcqmRgDlWylMX5E1dKoViMGjVKr7/+uv71r3+pWrVqjntffXx8VKlSJYvTlQ/VqlXLt/5ElSpVVKtWLdalMNH48eMVHh6u2bNnq1+/ftq7d6+WLl2qpUuXWh2tXOnVq5dmzZqlhg0bqnnz5jpw4IDi4+M1bNgwq6OVaRcuXNC3337reH38+HGlpqaqZs2aatiwocaNG6fZs2ercePGaty4sWbPnq3KlStr4MCBFqYGrMUcynrMoUoG5lAlA3Mo85W7+ZMdKAaSCtxeffVVq6OVax07drSPHTvW6hjlzoYNG+whISF2T09P+y233GJfunSp1ZHKnezsbPvYsWPtDRs2tHt5edmDg4PtU6dOtefk5FgdrUz76KOPCvz/gqFDh9rtdrs9Ly/PPm3aNHu9evXsnp6e9g4dOtg///xza0MDFmMOVTIxh7IGcyjrMYcyX3mbP9nsdrvdzBIMAAAAAAAAYE0pAAAAAAAAmI5SCgAAAAAAAKajlAIAAAAAAIDpKKUAAAAAAABgOkopAAAAAAAAmI5SCgAAAAAAAKajlAIAAAAAAIDpKKUAlHonTpyQzWZTamqq1VEcvvrqK915553y8vJS69atrY4DAADghPkTgJKAUgrAn/bwww/LZrNpzpw5TuPvvPOObDabRamsNW3aNFWpUkVHjhzRli1bCtzn+r+bzWZTxYoVFRwcrIkTJ+rixYtO+61bt0533323fHx8VLVqVbVs2VKxsbE6e/asGV8FAAAUA+ZP+TF/AsofSikALuHl5aW5c+fqp59+sjqKy1y5cuWGjz169KjuuusuBQQEqFatWoXu99e//lUZGRk6duyYZs6cqcTERE2cONHx/tSpU9W/f3/ddttteu+99/TFF1/ohRde0MGDB/Xaa6/dcD4AAGA95k/OmD8B5Q+lFACX6Nq1q+rVq6e4uLhC95k+fXq+S7ETEhIUGBjoeP3www+rT58+mj17tnx9fVW9enXNmDFDV69e1aRJk1SzZk01aNBAy5Yty3f+r776SuHh4fLy8lLz5s21detWp/cPHTqke+65R1WrVpWvr68GDx6s06dPO96/++67NXr0aEVHR6t27drq1q1bgd8jLy9PsbGxatCggTw9PdW6dWu9//77jvdtNptSUlIUGxsrm82m6dOnF/pv4unpqXr16snf318DBw7UoEGD9M4770iS9u7dq9mzZ+uFF17Qc889p/DwcAUGBqpbt25at26dhg4dKkk6ePCgOnXqpGrVqsnb21uhoaHat29foZ8JAABKBuZPzJ+A8o5SCoBLuLm5afbs2XrppZf0/fff/6lzffjhhzp16pS2b9+u+Ph4TZ8+XX/7299Uo0YNffLJJ4qMjFRkZKROnjzpdNykSZM0YcIEHThwQOHh4br33nt15swZSVJGRoY6duyo1q1ba9++fXr//ff1ww8/qF+/fk7nWLFihdzd3bVr1y4tWbKkwHz/+Mc/9MILL+j555/XZ599pu7du+vee+/VN9984/is5s2ba8KECcrIyHD6y90fqVSpkn799VdJ0urVq1W1alVFRUUVuG/16tUlSYMGDVKDBg306aefKiUlRVOmTFHFihWL/JkAAMAazJ+YPwHlHaUUAJe577771Lp1a02bNu1PnadmzZqaP3++br75Zg0bNkw333yzLl26pCeffFKNGzdWTEyMPDw8tGvXLqfjRo8erb59+6pp06ZatGiRfHx89Morr0iSFi1apFtvvVWzZ8/WLbfcojZt2mjZsmX66KOP9PXXXzvO0ahRI82bN08333yzbrnllgLzPf/883riiSc0YMAA3XzzzZo7d65at26thIQESVK9evXk7u6uqlWrql69eqpatWqRvvfevXv1+uuvq0uXLpKkb775RsHBwX84QUpLS1PXrl11yy23qHHjxnrggQfUqlWrIn0mAACwFvOnBEnMn4DyilIKgEvNnTtXK1as0KFDh274HM2bN1eFCv/9nydfX1+1aNHC8drNzU21atVSVlaW03Ft27Z1/Ozu7q6wsDAdPnxYkpSSkqKPPvpIVatWdWzXJ01Hjx51HBcWFva72bKzs3Xq1Cm1a9fOabxdu3aOzzLi3//+t6pWrSovLy+1bdtWHTp00EsvvSRJstvtRVroNDo6WiNGjFDXrl01Z84cp+8DAABKPuZPxjB/AsoOSikALtWhQwd1795dTz75ZL73KlSoILvd7jR2/VLr//Xbv2xdf7rKb8fy8vL+MM/1SUleXp569eql1NRUp+2bb75Rhw4dHPtXqVLlD8/5v+e9rqgToN/q1KmTUlNTdeTIEf3yyy9av3696tatK0lq0qSJjh49WuC/0f+aPn26vvzyS/Xs2VMffvihmjVrprfffttwFgAAYA3mT8YwfwLKDkopAC43Z84cbdiwQbt373Yar1OnjjIzM50mVqmpqS773D179jh+vnr1qlJSUhx/zbv11lv15ZdfKjAwUI0aNXLaijqRkiRvb2/5+flp586dTuO7d+9W06ZNDWeuUqWKGjVqpICAgHwTx4EDB+rChQtKTEws8Niff/7Z8XOTJk00fvx4ffDBB7r//vv16quvGs4CAACsw/yp6Jg/AWUHpRQAl2vRooUGDRrkuIz6urvvvls//vij5s2bp6NHj2rhwoV67733XPa5Cxcu1Ntvv62vvvpKo0aN0k8//aRhw4ZJkkaNGqWzZ8/qwQcf1N69e3Xs2DF98MEHGjZsmHJzcw19zqRJkzR37lwlJSXpyJEjmjJlilJTUzV27FiXfRdJuuOOOzR58mRNmDBBkydP1scff6zvvvtOW7Zs0QMPPKAVK1bo8uXLGj16tLZu3arvvvtOu3bt0qeffnpDEzwAAGAd5k+uwfwJKF0opQAUi2effTbfpeZNmzZVYmKiFi5cqFatWmnv3r2GnqzyR+bMmaO5c+eqVatW2rFjh/71r3+pdu3akiQ/Pz/t2rVLubm56t69u0JCQjR27Fj5+Pg4rb9QFGPGjNGECRM0YcIEtWjRQu+//77effddNW7c2GXf5bq5c+fq9ddf1yeffKLu3burefPmio6OVsuWLTV06FC5ubnpzJkzGjJkiJo0aaJ+/fqpR48emjFjhsuzAACA4sX8yTWYPwGlh83+2//VAwAAAAAAAIoZV0oBAAAAAADAdJRSAAAAAAAAMB2lFAAAAAAAAExHKQUAAAAAAADTUUoBAAAAAADAdJRSAAAAAAAAMB2lFAAAAAAAAExHKQUAAAAAAADTUUoBAAAAAADAdJRSAAAAAAAAMB2lFAAAAAAAAExHKQUAAAAAAADT/T+/Q/V77RU2tAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].bar(np.arange(10) + 1, pca.explained_variance_ratio_)\n",
    "ax[1].bar(np.arange(10) + 1, np.cumsum(pca.explained_variance_ratio_))\n",
    "ax[0].set_xlabel('Number of PCs')\n",
    "ax[0].set_ylabel('Proportion of explained variance')\n",
    "ax[1].set_xlabel('Number of PCs')\n",
    "ax[1].set_ylabel('Proportion of retained variance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code constructs a new DataFrame that combines the original target variable (`mpg`) with the first 10 principal components obtained from Principal Component Analysis (PCA), and then sets the display format for floating-point numbers.\n",
    "\n",
    "First, `pca.transform(cars_norm)` projects the standardized feature data (`cars_norm`) onto the principal component axes, resulting in a new array where each column represents a principal component. This array is then converted into a DataFrame, with columns named `'PC1'`, `'PC2'`, ..., `'PC10'`. The column names are generated by creating a range from 1 to 10, converting it to a pandas Index, and then to strings prefixed with `'PC'`.\n",
    "\n",
    "Next, `pd.concat([cars['mpg'], ...], axis=1)` horizontally concatenates the original `mpg` column from the `cars` DataFrame with the new principal component DataFrame. The result is a new DataFrame, `cars_pc`, where the first column is `mpg` and the remaining columns are the first 10 principal components.\n",
    "\n",
    "The line `pd.options.display.float_format = '{:.2f}'.format` sets the display format for floating-point numbers to two decimal places, making the output easier to read when the DataFrame is displayed.\n",
    "\n",
    "Finally, `cars_pc` is evaluated, which in a notebook environment displays the combined DataFrame. This allows you to see both the original target variable and the transformed features side by side, which is useful for further analysis or modeling using the principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mpg   PC1   PC2   PC3   PC4   PC5   PC6   PC7   PC8   PC9  PC10\n",
      "0  21.00 -0.63  1.74 -0.67  0.10 -0.93 -0.05 -0.40 -0.18  0.07  0.16\n",
      "1  21.00 -0.61  1.55 -0.43  0.19 -1.03  0.16 -0.42 -0.09  0.13  0.07\n",
      "2  22.80 -2.80 -0.12 -0.41 -0.26  0.45  0.51 -0.29 -0.08 -0.16 -0.18\n",
      "3  21.40 -0.26 -2.36 -0.10 -0.51  0.55  0.04 -0.06 -0.19  0.10  0.17\n",
      "4  18.70  2.03 -0.77 -1.02  0.08  0.20 -0.16  0.29  0.12  0.11  0.18\n",
      "5  18.10 -0.20 -2.78  0.09 -1.00  0.23  0.32 -0.15 -0.05  0.15 -0.03\n",
      "6  14.30  2.85  0.32 -0.32 -0.05  0.42 -0.69 -0.20  0.18 -0.36  0.20\n",
      "7  24.40 -1.94 -1.45  0.96 -0.14 -0.35 -0.07  0.64 -0.37 -0.24  0.03\n",
      "8  22.80 -2.30 -1.96  1.75  0.30 -0.41  0.26  0.54  0.94  0.06  0.13\n",
      "9  19.20 -0.64 -0.15  1.43  0.07  0.01 -0.85  0.17 -0.54  0.26 -0.12\n",
      "10 17.80 -0.71 -0.31  1.57  0.09 -0.06 -0.75  0.16 -0.34  0.34 -0.07\n",
      "11 16.40  2.17 -0.70 -0.32 -0.13 -0.38 -0.19 -0.10  0.09  0.06 -0.39\n",
      "12 17.30  2.01 -0.70 -0.41 -0.21 -0.35 -0.31 -0.10  0.29  0.12 -0.18\n",
      "13 15.20  1.98 -0.81 -0.30 -0.18 -0.41 -0.22 -0.11  0.41  0.17 -0.18\n",
      "14 10.40  3.54 -0.84  0.65  0.30 -0.14  0.90 -0.09 -0.23 -0.05  0.26\n",
      "15 10.40  3.60 -0.75  0.73  0.42 -0.09  0.88 -0.12 -0.25 -0.12  0.04\n",
      "16 14.70  3.49 -0.45  0.70  0.70  0.07  0.61 -0.15 -0.18 -0.20 -0.15\n",
      "17 32.40 -3.33 -0.29 -0.28  0.07  0.11  0.42 -0.31  0.07  0.12 -0.13\n",
      "18 30.40 -3.88  0.70 -0.20  1.19  0.13 -0.54 -0.41 -0.13  0.23  0.28\n",
      "19 33.90 -3.64 -0.28 -0.29  0.21  0.11  0.25 -0.30  0.37  0.23  0.06\n",
      "20 21.50 -1.96 -2.10  0.03  0.04  0.16 -0.67 -0.16  0.31 -0.61  0.03\n",
      "21 15.50  2.05 -1.03 -1.18 -0.60 -0.18 -0.09  0.23 -0.16  0.12  0.02\n",
      "22 15.20  1.68 -0.91 -1.01 -0.01 -0.18 -0.27  0.22  0.06  0.25 -0.01\n",
      "23 13.30  2.66  0.67 -0.18  0.82  0.51 -0.90 -0.19 -0.02 -0.36 -0.10\n",
      "24 19.20  2.35 -0.90 -0.87  0.16  0.23  0.17  0.33 -0.08  0.08  0.19\n",
      "25 27.30 -3.36 -0.10 -0.51 -0.02  0.22  0.21 -0.28 -0.02  0.06 -0.03\n",
      "26 26.00 -2.44  2.06 -0.88  0.57 -0.62  0.30  1.03  0.01 -0.40 -0.12\n",
      "27 30.40 -2.95  1.38 -0.36 -1.16  0.68  0.02  0.47 -0.24 -0.17  0.10\n",
      "28 15.80  1.21  3.50 -0.20  0.60  1.12  0.34  0.66  0.15  0.43 -0.13\n",
      "29 19.70 -0.01  3.22  0.37 -0.96 -0.85 -0.08  0.02 -0.11 -0.14  0.05\n",
      "30 15.00  2.54  4.37  1.43 -0.87  0.42  0.01 -0.41  0.46 -0.03  0.09\n",
      "31 21.40 -2.51  0.26  0.23  0.21  0.36  0.46 -0.50 -0.17 -0.23 -0.22\n"
     ]
    }
   ],
   "source": [
    "cars_pc = pd.concat([cars['mpg'],\n",
    "                     pd.DataFrame(pca.transform(cars_norm), \n",
    "                                  columns='PC' + \n",
    "                     (pd.Index(range(10)) + 1).astype(str))], axis=1)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "print(cars_pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs a multiple linear regression analysis using the `statsmodels` library, modeling the relationship between the target variable `mpg` (miles per gallon) and the first ten principal components (`PC1` through `PC10`) derived from Principal Component Analysis (PCA). The formula `'mpg ~ PC1 + PC2 + ... + PC10'` specifies that `mpg` is the dependent variable, while the ten principal components are the independent variables (predictors). The data for the regression comes from the `cars_pc` DataFrame, which contains both the original `mpg` values and the computed principal components.\n",
    "\n",
    "The `.fit()` method estimates the regression coefficients for each principal component by minimizing the sum of squared residuals between the observed and predicted `mpg` values. After fitting the model, `.summary()` generates a detailed statistical summary, including the estimated coefficients, their standard errors, t-statistics, p-values, R-squared value, and other diagnostic metrics. This summary helps you assess how well the principal components collectively explain the variation in `mpg` and which components are most influential in the model. Using principal components as predictors can help address issues of multicollinearity and reduce the dimensionality of the original feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.869</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   13.93</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 May 2025</td> <th>  Prob (F-statistic):</th> <td>3.79e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:34:22</td>     <th>  Log-Likelihood:    </th> <td> -69.855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   161.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   177.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   20.0906</td> <td>    0.468</td> <td>   42.884</td> <td> 0.000</td> <td>   19.116</td> <td>   21.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC1</th>       <td>   -2.2454</td> <td>    0.195</td> <td>  -11.503</td> <td> 0.000</td> <td>   -2.651</td> <td>   -1.839</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC2</th>       <td>    0.1145</td> <td>    0.288</td> <td>    0.398</td> <td> 0.695</td> <td>   -0.484</td> <td>    0.713</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC3</th>       <td>   -1.2788</td> <td>    0.606</td> <td>   -2.109</td> <td> 0.047</td> <td>   -2.540</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC4</th>       <td>   -0.0886</td> <td>    0.902</td> <td>   -0.098</td> <td> 0.923</td> <td>   -1.965</td> <td>    1.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC5</th>       <td>    0.3079</td> <td>    0.994</td> <td>    0.310</td> <td> 0.760</td> <td>   -1.759</td> <td>    2.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC6</th>       <td>    0.3781</td> <td>    1.022</td> <td>    0.370</td> <td> 0.715</td> <td>   -1.747</td> <td>    2.504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC7</th>       <td>    0.2562</td> <td>    1.285</td> <td>    0.199</td> <td> 0.844</td> <td>   -2.416</td> <td>    2.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC8</th>       <td>    1.0842</td> <td>    1.649</td> <td>    0.657</td> <td> 0.518</td> <td>   -2.346</td> <td>    4.514</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC9</th>       <td>    1.2618</td> <td>    2.023</td> <td>    0.624</td> <td> 0.539</td> <td>   -2.944</td> <td>    5.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC10</th>      <td>    3.4583</td> <td>    3.037</td> <td>    1.139</td> <td> 0.268</td> <td>   -2.857</td> <td>    9.774</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.907</td> <th>  Durbin-Watson:     </th> <td>   1.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.385</td> <th>  Jarque-Bera (JB):  </th> <td>   1.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.521</td> <th>  Prob(JB):          </th> <td>   0.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.526</td> <th>  Cond. No.          </th> <td>    15.6</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       mpg        & \\textbf{  R-squared:         } &     0.869   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.807   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     13.93   \\\\\n",
       "\\textbf{Date:}             & Mon, 12 May 2025 & \\textbf{  Prob (F-statistic):} &  3.79e-07   \\\\\n",
       "\\textbf{Time:}             &     19:34:22     & \\textbf{  Log-Likelihood:    } &   -69.855   \\\\\n",
       "\\textbf{No. Observations:} &          32      & \\textbf{  AIC:               } &     161.7   \\\\\n",
       "\\textbf{Df Residuals:}     &          21      & \\textbf{  BIC:               } &     177.8   \\\\\n",
       "\\textbf{Df Model:}         &          10      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      20.0906  &        0.468     &    42.884  &         0.000        &       19.116    &       21.065     \\\\\n",
       "\\textbf{PC1}       &      -2.2454  &        0.195     &   -11.503  &         0.000        &       -2.651    &       -1.839     \\\\\n",
       "\\textbf{PC2}       &       0.1145  &        0.288     &     0.398  &         0.695        &       -0.484    &        0.713     \\\\\n",
       "\\textbf{PC3}       &      -1.2788  &        0.606     &    -2.109  &         0.047        &       -2.540    &       -0.018     \\\\\n",
       "\\textbf{PC4}       &      -0.0886  &        0.902     &    -0.098  &         0.923        &       -1.965    &        1.788     \\\\\n",
       "\\textbf{PC5}       &       0.3079  &        0.994     &     0.310  &         0.760        &       -1.759    &        2.375     \\\\\n",
       "\\textbf{PC6}       &       0.3781  &        1.022     &     0.370  &         0.715        &       -1.747    &        2.504     \\\\\n",
       "\\textbf{PC7}       &       0.2562  &        1.285     &     0.199  &         0.844        &       -2.416    &        2.929     \\\\\n",
       "\\textbf{PC8}       &       1.0842  &        1.649     &     0.657  &         0.518        &       -2.346    &        4.514     \\\\\n",
       "\\textbf{PC9}       &       1.2618  &        2.023     &     0.624  &         0.539        &       -2.944    &        5.468     \\\\\n",
       "\\textbf{PC10}      &       3.4583  &        3.037     &     1.139  &         0.268        &       -2.857    &        9.774     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.907 & \\textbf{  Durbin-Watson:     } &    1.861  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.385 & \\textbf{  Jarque-Bera (JB):  } &    1.747  \\\\\n",
       "\\textbf{Skew:}          &  0.521 & \\textbf{  Prob(JB):          } &    0.418  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.526 & \\textbf{  Cond. No.          } &     15.6  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.869\n",
       "Model:                            OLS   Adj. R-squared:                  0.807\n",
       "Method:                 Least Squares   F-statistic:                     13.93\n",
       "Date:                Mon, 12 May 2025   Prob (F-statistic):           3.79e-07\n",
       "Time:                        19:34:22   Log-Likelihood:                -69.855\n",
       "No. Observations:                  32   AIC:                             161.7\n",
       "Df Residuals:                      21   BIC:                             177.8\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     20.0906      0.468     42.884      0.000      19.116      21.065\n",
       "PC1           -2.2454      0.195    -11.503      0.000      -2.651      -1.839\n",
       "PC2            0.1145      0.288      0.398      0.695      -0.484       0.713\n",
       "PC3           -1.2788      0.606     -2.109      0.047      -2.540      -0.018\n",
       "PC4           -0.0886      0.902     -0.098      0.923      -1.965       1.788\n",
       "PC5            0.3079      0.994      0.310      0.760      -1.759       2.375\n",
       "PC6            0.3781      1.022      0.370      0.715      -1.747       2.504\n",
       "PC7            0.2562      1.285      0.199      0.844      -2.416       2.929\n",
       "PC8            1.0842      1.649      0.657      0.518      -2.346       4.514\n",
       "PC9            1.2618      2.023      0.624      0.539      -2.944       5.468\n",
       "PC10           3.4583      3.037      1.139      0.268      -2.857       9.774\n",
       "==============================================================================\n",
       "Omnibus:                        1.907   Durbin-Watson:                   1.861\n",
       "Prob(Omnibus):                  0.385   Jarque-Bera (JB):                1.747\n",
       "Skew:                           0.521   Prob(JB):                        0.418\n",
       "Kurtosis:                       2.526   Cond. No.                         15.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('mpg ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8 + PC9 + PC10', data=cars_pc).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code fits a multiple linear regression model using the `statsmodels` library to predict the `mpg` (miles per gallon) variable based on the first three principal components (`PC1`, `PC2`, and `PC3`) from a PCA transformation. The formula `'mpg ~ PC1 + PC2 + PC3'` specifies that `mpg` is the dependent variable, while `PC1`, `PC2`, and `PC3` are the independent variables.\n",
    "\n",
    "The `smf.ols(...).fit()` part creates and fits the Ordinary Least Squares (OLS) regression model to the data in the `cars_pc` DataFrame. The `.summary()` method then generates a detailed statistical summary of the fitted model, including the estimated coefficients for each principal component, their standard errors, t-statistics, p-values, the R-squared value, and other diagnostic metrics.\n",
    "\n",
    "By using principal components as predictors, this approach helps address multicollinearity among the original features and reduces the dimensionality of the regression problem. The summary output allows you to assess how well these three principal components explain the variation in `mpg` and to interpret the statistical significance and effect size of each component in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.854</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.838</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   54.61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 May 2025</td> <th>  Prob (F-statistic):</th> <td>8.02e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:34:22</td>     <th>  Log-Likelihood:    </th> <td> -71.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   151.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    28</td>      <th>  BIC:               </th> <td>   157.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   20.0906</td> <td>    0.428</td> <td>   46.909</td> <td> 0.000</td> <td>   19.213</td> <td>   20.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC1</th>       <td>   -2.2454</td> <td>    0.178</td> <td>  -12.583</td> <td> 0.000</td> <td>   -2.611</td> <td>   -1.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC2</th>       <td>    0.1145</td> <td>    0.263</td> <td>    0.435</td> <td> 0.667</td> <td>   -0.424</td> <td>    0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC3</th>       <td>   -1.2788</td> <td>    0.554</td> <td>   -2.307</td> <td> 0.029</td> <td>   -2.414</td> <td>   -0.144</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.348</td> <th>  Durbin-Watson:     </th> <td>   1.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.510</td> <th>  Jarque-Bera (JB):  </th> <td>   1.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.442</td> <th>  Prob(JB):          </th> <td>   0.566</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.733</td> <th>  Cond. No.          </th> <td>    3.11</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       mpg        & \\textbf{  R-squared:         } &     0.854   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.838   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     54.61   \\\\\n",
       "\\textbf{Date:}             & Mon, 12 May 2025 & \\textbf{  Prob (F-statistic):} &  8.02e-12   \\\\\n",
       "\\textbf{Time:}             &     19:34:22     & \\textbf{  Log-Likelihood:    } &   -71.586   \\\\\n",
       "\\textbf{No. Observations:} &          32      & \\textbf{  AIC:               } &     151.2   \\\\\n",
       "\\textbf{Df Residuals:}     &          28      & \\textbf{  BIC:               } &     157.0   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      20.0906  &        0.428     &    46.909  &         0.000        &       19.213    &       20.968     \\\\\n",
       "\\textbf{PC1}       &      -2.2454  &        0.178     &   -12.583  &         0.000        &       -2.611    &       -1.880     \\\\\n",
       "\\textbf{PC2}       &       0.1145  &        0.263     &     0.435  &         0.667        &       -0.424    &        0.653     \\\\\n",
       "\\textbf{PC3}       &      -1.2788  &        0.554     &    -2.307  &         0.029        &       -2.414    &       -0.144     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.348 & \\textbf{  Durbin-Watson:     } &    1.906  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.510 & \\textbf{  Jarque-Bera (JB):  } &    1.138  \\\\\n",
       "\\textbf{Skew:}          &  0.442 & \\textbf{  Prob(JB):          } &    0.566  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.733 & \\textbf{  Cond. No.          } &     3.11  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.854\n",
       "Model:                            OLS   Adj. R-squared:                  0.838\n",
       "Method:                 Least Squares   F-statistic:                     54.61\n",
       "Date:                Mon, 12 May 2025   Prob (F-statistic):           8.02e-12\n",
       "Time:                        19:34:22   Log-Likelihood:                -71.586\n",
       "No. Observations:                  32   AIC:                             151.2\n",
       "Df Residuals:                      28   BIC:                             157.0\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     20.0906      0.428     46.909      0.000      19.213      20.968\n",
       "PC1           -2.2454      0.178    -12.583      0.000      -2.611      -1.880\n",
       "PC2            0.1145      0.263      0.435      0.667      -0.424       0.653\n",
       "PC3           -1.2788      0.554     -2.307      0.029      -2.414      -0.144\n",
       "==============================================================================\n",
       "Omnibus:                        1.348   Durbin-Watson:                   1.906\n",
       "Prob(Omnibus):                  0.510   Jarque-Bera (JB):                1.138\n",
       "Skew:                           0.442   Prob(JB):                        0.566\n",
       "Kurtosis:                       2.733   Cond. No.                         3.11\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('mpg ~ PC1 + PC2 + PC3', data=cars_pc).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code fits a multiple linear regression model using the `statsmodels` library to predict the `mpg` (miles per gallon) variable based on just two principal components, `PC1` and `PC3`, from a PCA transformation. The formula `'mpg ~ PC1 + PC3'` specifies that `mpg` is the dependent variable, while `PC1` and `PC3` are the independent variables (predictors).\n",
    "\n",
    "The `smf.ols(...).fit()` part creates and fits the Ordinary Least Squares (OLS) regression model to the data in the `cars_pc` DataFrame, which contains both the original `mpg` values and the principal components. The `.summary()` method then generates a detailed statistical summary of the fitted model, including the estimated coefficients for each principal component, their standard errors, t-statistics, p-values, the R-squared value, and other diagnostic metrics.\n",
    "\n",
    "By using only selected principal components as predictors, this approach further reduces the dimensionality of the regression problem and may help focus on the most informative directions in the data. The summary output allows you to assess how well these two principal components explain the variation in `mpg` and to interpret the statistical significance and effect size of each component in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.853</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   84.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 12 May 2025</td> <th>  Prob (F-statistic):</th> <td>8.39e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:34:22</td>     <th>  Log-Likelihood:    </th> <td> -71.694</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   149.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    29</td>      <th>  BIC:               </th> <td>   153.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   20.0906</td> <td>    0.422</td> <td>   47.579</td> <td> 0.000</td> <td>   19.227</td> <td>   20.954</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC1</th>       <td>   -2.2454</td> <td>    0.176</td> <td>  -12.762</td> <td> 0.000</td> <td>   -2.605</td> <td>   -1.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC3</th>       <td>   -1.2788</td> <td>    0.546</td> <td>   -2.340</td> <td> 0.026</td> <td>   -2.396</td> <td>   -0.161</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.232</td> <th>  Durbin-Watson:     </th> <td>   1.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.540</td> <th>  Jarque-Bera (JB):  </th> <td>   1.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.423</td> <th>  Prob(JB):          </th> <td>   0.585</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.702</td> <th>  Cond. No.          </th> <td>    3.11</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       mpg        & \\textbf{  R-squared:         } &     0.853   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.843   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     84.18   \\\\\n",
       "\\textbf{Date:}             & Mon, 12 May 2025 & \\textbf{  Prob (F-statistic):} &  8.39e-13   \\\\\n",
       "\\textbf{Time:}             &     19:34:22     & \\textbf{  Log-Likelihood:    } &   -71.694   \\\\\n",
       "\\textbf{No. Observations:} &          32      & \\textbf{  AIC:               } &     149.4   \\\\\n",
       "\\textbf{Df Residuals:}     &          29      & \\textbf{  BIC:               } &     153.8   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      20.0906  &        0.422     &    47.579  &         0.000        &       19.227    &       20.954     \\\\\n",
       "\\textbf{PC1}       &      -2.2454  &        0.176     &   -12.762  &         0.000        &       -2.605    &       -1.886     \\\\\n",
       "\\textbf{PC3}       &      -1.2788  &        0.546     &    -2.340  &         0.026        &       -2.396    &       -0.161     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.232 & \\textbf{  Durbin-Watson:     } &    1.928  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.540 & \\textbf{  Jarque-Bera (JB):  } &    1.072  \\\\\n",
       "\\textbf{Skew:}          &  0.423 & \\textbf{  Prob(JB):          } &    0.585  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.702 & \\textbf{  Cond. No.          } &     3.11  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.853\n",
       "Model:                            OLS   Adj. R-squared:                  0.843\n",
       "Method:                 Least Squares   F-statistic:                     84.18\n",
       "Date:                Mon, 12 May 2025   Prob (F-statistic):           8.39e-13\n",
       "Time:                        19:34:22   Log-Likelihood:                -71.694\n",
       "No. Observations:                  32   AIC:                             149.4\n",
       "Df Residuals:                      29   BIC:                             153.8\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     20.0906      0.422     47.579      0.000      19.227      20.954\n",
       "PC1           -2.2454      0.176    -12.762      0.000      -2.605      -1.886\n",
       "PC3           -1.2788      0.546     -2.340      0.026      -2.396      -0.161\n",
       "==============================================================================\n",
       "Omnibus:                        1.232   Durbin-Watson:                   1.928\n",
       "Prob(Omnibus):                  0.540   Jarque-Bera (JB):                1.072\n",
       "Skew:                           0.423   Prob(JB):                        0.585\n",
       "Kurtosis:                       2.702   Cond. No.                         3.11\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('mpg ~ PC1 + PC3', data=cars_pc).fit().summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
